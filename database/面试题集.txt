['1什么是特征归一化。对数值类型的特征做归一化可以将所有的特征都统一到一个大致相同的数值区间内', '2为什么要特征归一化。为了消除数据特征之间的量纲影响我们需要对特征进行归一化处理使得不同指标之间具有可比性例如分析一个人的身高和体重对健康的影响如果使用米m和千克kg作为单位那么身高特征会在1618m的数值范围内体重特征会在50100kg的范围内分析出来的结果显然会倾向于数值差别比较大的体重特征想要得到更为准确的结果就需要进行特征归一化Normalization处理使各指标处于同一数值量级以便进行分析', '3特征归一化常用的方法。 线性函数归一化MinMax Scaling它对原始数据进行线性变换使结果映射到01的范围实现对原始数据的等比缩放。 零均值归一化ZScore Normalization它会将原始数据映射到均值为0标准差为1的分布上', '4归一化处理适用模型。 应用归一化的模型在实际应用中通过梯度下降法求解的模型通常是需要归一化的包括线性回归逻辑回归支持向量机神经网络等模型。 不使用归一化的模型如决策树。 2 图像样本增强', '1在图像分类任务中训练数据不足会带来什么问题。当训练数据不足时说明模型从原始数据中获取的信息比较少这种情况下要想保证模型的效果就需要更多先验信息具体到图像分类任务上训练数据不足带来的问题主要表现在过拟合方面即模型在训练样本上的效果可能不错但在测试集上的泛化效果不佳', '2如何缓解数据量不足带来的问题。 一定程度内的随机旋转平移缩放裁剪填充左右翻转等这些变换对应着同一个目标在不同角度的观察结果。 对图像中的像素添加噪声扰动比如椒盐噪声高斯白噪声等。 颜色变换。 改变图像的亮度清晰度对比度锐度等。 3 什么是监督学习非监督学习', '1监督学习。监督学习是使用已知正确答案的示例来训练网络已知数据和其一一对应的标签训练一个预测模型将输入数据映射到标签的过程', '2非监督学习。在非监督式学习中数据并不被特别标识适用于你具有数据集但无标签的情况学习模型是为了推断出数据的一些内在结构', '4 监督学习非监督学习主要应用场景。1监督学习回归分类。2非监督学习聚类PCAGANGMM。 二模型评估重点', '1 回归问题模型评估指标。 平均绝对误差Mean Absolute Deviation单个观测值与算术平均值的偏差的绝对值的平均。 均方误差单个样本到平均值差值的平方平均值。 MAD中位数绝对偏差与数据中值绝对偏差的中值。 R2决定系数趋向于1模型越好趋向于0模型越差', '2 分类问题模型评估指标。查准率Precision分类正确数量  分类正确数量  多分类的数量范围01简单说来就是分类对不对。召回率Precision分类正确数量  分类正确数量  少分类的数量范围01简单说来就是分类全不全。F1得分2  查询率  召回率   查准率  召回率 范围0 1 综合考虑了查准率召回率。 3 AB测试', '1什么是AB测试。AB测试就是两种模型同时运行并在实际环境中验证其效果的方式在互联网公司中AB 测试是验证新模块新功能新产品是否有效新算法新模型的效果是否有提升新设计是否受到用户欢迎新更改是否影响用户体验的主要测试方法在机器学习领域中AB 测试是验证模型最终效果的主要手段', '2为什么需要AB测试。 离线评估无法完全消除模型过拟合的影响因此得出的离线评估结果无法完全替代线上评估结果。 离线评估无法完全还原线上的工程环境一般来讲离线评估往往不会考虑线上环境的延迟数据丢失标签数据缺失等情况因此离线评估的结果是理想工程环境下的结果。 线上系统的某些商业指标在离线评估中无法计算', '3如何进行线上AB测试。进行AB测试的主要手段是进行用户分桶即将用户分成实验组和对照组对实验组的用户施以新模型对对照组的用户施以旧模型在分桶的过程中要注意样本的独立性和采样方式的无偏性确保同一个用户每次只能分到同一个桶中在分桶过程中所选取的user_id需要是一个随机数这样才能保证桶中的样本是无偏的。 4 超参数重点', '1什么是超参数。超参数是在开始学习过程之前设置值的参数而不是通过训练得到的参数数据', '2超参数有哪些调优手段nan', '3常用超参数对模型的性能影响nan', '1什么是欠拟合过拟合。欠拟合指的是模型在训练和预测时表现都不好的情况过拟合是指模型对于训练数据拟合呈过当的情况反映到评估指标上就是模型在训练集上的表现很好但在测试集和新数据上的表现较差', '2如何避免过拟合。 扩大样本数据使用更多的训练数据是解决过拟合问题最有效的手段因为更多的样本能够让模型学习到更多更有效的特征减小噪声的影响。 降低模型复杂度在数据较少时模型过于复杂是产生过拟合的主要因素适当降低模型复杂度可以避免模型拟合过多的采样噪声例如在神经网络模型中减少网络层数神经元个数等在决策树模型中降低树的深度进行剪枝等。 正则化方法给模型的参数加上一定的正则约束比如将权值的大小加入到损失函数中。 集成学习方法集成学习是把多个模型集成在一起来降低单一模型的过拟合风险。 减少训练迭代次数提前停止训练。 神经网络中加入dropout操作层或者采用BN。 主动加入噪声数据样本', '3如何避免欠拟合。 添加新特征当特征不足或者现有特征与样本标签的相关性不强时模型容易出现欠拟合。 增加模型复杂度简单模型的学习能力较差通过增加模型的复杂度可以使模型拥有更强的拟合能力例如在线性模型中添加高次项在神经网络模型中增加网络层数或神经元个数等。 减小正则化系数正则化是用来防止过拟合的但当模型出现欠拟合现象时则需要有针对性地减小正则化系数', '6 什么是置信概率。置信概率Confidence Probability是用来衡量推断靠程度的概率该值越大说明推断结果确定性越大该值越小说明推断结果不确定性越大', '7 什么是交叉验证。交叉验证指将含有N个样本的数据集分成K份每份含有NK个样本选择其中1份作为测试集另外K1份作为训练集测试集就有K种情况将K种情况下模型的泛化误差取均值得到模型最终的泛化误差。交叉验证的作用是为了得到更为稳健可靠的模型对模型的泛化误差进行评估', '8 列举解决类别不均衡问题的方法重点。1扩大数据集增加包含小类样本数据的数据更多的数据能得到更多的分布信息。2对大类数据欠采样减少大类数据样本个数使与小样本个数接近对少量样本类别进行随机过采样即对样本较少的类别进行复制使得样本数量均衡。3使用新评价指标如果当前评价指标不适用则应寻找其他具有说服力的评价指标。4选择新算法不同的算法适用于不同的任务与数据应该使用不同的算法进行比较。5数据代价加权例如当分类任务是识别小类那么可以对分类器的小类样本数据增加权值降低大类样本的权值从而使得分类器将重点集中在小类样本身上。6随机过采样随机对数量较少的类别样本进行复制', '9 什么是L1L2正则化。机器学习中几乎都可以看到损失函数后面会添加一个额外项常用的额外项一般有两种一般英文称作 L1norm 和L2norm中文称作 L1正则化 和 L2正则化或者 L1范数 和 L2范数L1正则化和L2正则化可以看做是损失函数的惩罚项所谓惩罚是指对损失函数中的某些参数做一些限制范数的表达式为。x_psumx_ipfrac1p。当p1时是L1范数其表示某个向量中所有元素绝对值的和。当p2时是L2范数 表示某个向量中所有元素平方和再开根 也就是欧几里得距离公式。正则化通过降低模型的复杂性 达到避免过拟合的问题原因是1而加入正则能抑制系数过大的问题2从贝叶斯的角度来分析 正则化是为模型参数估计增加一个先验知识先验知识会引导损失函数最小值过程朝着约束方向迭代。 10 神经网络权重初始值如何设置。在神经网络的学习中权重的初始值特别重要实际上设定什么样的权重初始值经常关系到神经网络的学习能否成功', '1权重初始值不能设置为0。如果把权重初始值全部设为0在误差反向传播法中所有的权重值都会进行相同的更新神经网络将无法正常学习比如在2层神经网络中假设第1层和第2层的权重为0这样一来正向传播时因为输入层的权重为0所以第2层的神经元全部会被传递相同的值第2层的神经元中全部输入相同的值这意味着反向传播时第2层的权重全部都会进行相同的更新因此权重被更新为相同的值并拥有了对称的值重复的值这使得神经网络拥有许多不同的权重的意义丧失了为了防止权重均一化严格地讲是为了瓦解权重的对称结构必须随机生成初始值', '2隐藏层激活值的分布。使用一个包含5层的神经网络每层有100个神经元然后用高斯分布随机生成1000个数据作为输入数据并把它们传给5层神经网络观察激活值的分布并绘制直方图从而反映激活值的分布情况。① Sigmoid激活函数的参数分布。 高斯权重初始值。sigmoid激活值分布imgsigmoid激活值分布png。上图显示的是标准差为1的随机权重激活值分布由图可见各层激活值呈偏向0和1的分布偏向0和1的数据分布会造成反向传播中梯度的值不断变小最后消失这个问题称为梯度消失gradient vanishing将参数初始值的标准差设置为001各层激活值分布如下图所示。sigmoid激活值分布_001imgsigmoid激活值分布_001png。由图可见当初始化权重参数时标准差为001激活值集中在05附近分布虽然没有出现梯度消失情况但激活值的分布有所偏向说明在表现力上会有很大问题因为如果有多个神经元都输出几乎相同的值那它们就没有存在的意义了。 Xavier初始值。Xavier Glorot和Yushua Bengio等人的论文Understanding the difficulty of training deep feedforward neural networks2010年中推荐的权重初始值俗称Xavier初始值现在在一般的深度学习框架中Xavier初始值已被作为标准使用为了使各层的激活值呈现出具有相同广度的分布论文建议如果前一层的节点数为n则初始值使用frac1sqrt n标准差为的分布使用Xavier初始值后前一层的节点数越多要设定为目标节点的初始值的权重尺度就越小。Xavier初始值激活分布imgXavier初始值激活分布png。由图可见Xavier初始值后面的隐藏层的分布呈稍微歪斜的形状如果用tanh函数双曲线函数代替sigmoid函数这个稍微歪斜的问题就能得到改善呈漂亮的吊钟型分布。② Relu激活函数参数分布。Xavier初始值同样适合Relu激活函数但当激活函数使用ReLU时一般推荐使用ReLU专用的初始值也就是Kaiming He等人推荐的初始值也称为He初始值当前一层的节点数为n时He初始值使用标准差为sqrtfrac2n的高斯分布可以直观理解为ReLU的负值区域的值为0为了使它更有广度所以需要2倍的系数。Relu高斯分布001imgRelu高斯分布001png。ReluXavier初始值imgReluXavier初始值png。ReluHe初始值imgReluHe初始值png。由上图可知当std  001时各层的激活值非常小神经网络上传递的是非常小的值说明逆向传播时权重的梯度也同样很小使用Xavier初始值随着层的加深偏向一点点变大层次较深时会出现梯度消失问题而当初始值为He初始值时各层中分布的广度相同由于即便层加深数据的广度也能保持不变因此逆向传播时也会传递合适的值。 三回归问题。 1 线性回归', '1什么是线性回归。线性回归是指通过数据样本找到一个最佳拟合数据样本的线性模型并用于预测线性方程的一般表达形式为。y  w_0  w_1x。其中x和y为已知w_0 w_1是要经过学习获得的参数', '2什么情况下使用线性回归。 数据样本呈线性分布在二维平面中线性分布的特征是数据呈一个狭长的条状分布并且没有明显弯曲。 已知模型为线性模型', '3线性回归的特点。① 优点。 思想简单实现容易建模迅速对于小数据量简单的关系很有效。 是许多强大的非线性模型的基础。 线性回归模型十分容易理解结果具有很好的可解释性有利于决策分析。 蕴含机器学习中的很多重要思想。② 缺点。 对于非线性数据或者数据特征间具有相关性多项式回归难以建模。 难以很好地表达高度复杂的数据', '4多元回归。多元回归是线性回归的推广含有一个变量称为线性回归含有多个变量称为多元回归多元回归的表达式为。y  w_0  w_1x_1  w_2x_2    w_nx_n。只有一个变量的时候模型是平面中的一条直线有两个变量的时候模型是空间中的一个平面有更多变量时模型将是更高维的。 2 多项式回归', '1什么是多项式回归。多项式回归是指使根据样本数据用高次多项式模型来最佳程度拟合样本的回归方法多项式回归中加入了特征的更高次方例如平方项或立方项也相当于增加了模型的自由度用来捕获数据中非线性的变化多项式回归模型一般表达式为。y  w_0  w_1x  w_2x2  w_3x  3    w_nxn。', '2什么情况下使用多项式回归。在回归分析中有时会遇到线性回归的直线拟合效果不佳如果发现散点图中数据点呈多项式曲线时可以考虑使用多项式回归来分析', '3多项式回归的特点。① 优点。 添加高阶项的时候也增加了模型的复杂度随着模型复杂度的升高模型的容量以及拟合数据的能力增加。② 缺点。 需要一些数据的先验知识才能选择最佳指数。 如果指数选择不当容易出现过拟合。 3 决策树回归', '1什么是决策树。决策树Decision Tree的核心思想是相似的输入必然产生相似的数据同因同果决策树通过把数据样本分配到树状结构的某个叶子节点来确定数据集中样本所属的分类决策树可用于回归和分类当用于回归时预测结果为叶子节点所有样本的均值。img决策子树1png。我们使用熵来度量系统的混乱或有序程度随着子表的划分信息熵越来越小信息越来越纯数据越来越有序同一个子节点下的数据越来越相同或相似信息熵表达式为。H  sum_i1nPx_ilog_2Px_i。其中Px_i是某个分类的概率当n的分类越大H的值越大当n1时信息熵为0在构建决策树时首先选择信息增益率大的属性作为分支判断的依据', '2决策树的特点nan', '3什么情况下使用决策树。 适合与标称型在有限目标集中取值属性较多的样本数据。 具有较广的适用性当对模型不确定时可以使用决策树进行验证', '4随机森林。随机抽取部分样本和随机抽取部分特征相结合构建多棵决策树这样不仅削弱了强势样本对预测结果的印象同时削弱了强势特征的影响提高了模型的泛化能力。 四分类问题。 1 二元分类', '1什么是二元分类。二元分类又称逻辑回归是将一组样本划分到两个不同类别的分类方式', '2如何实现二元分类。逻辑回归属于广义线性回归模型generalized linear model使用线性模型计算函数值再通过逻辑函数将连续值进行离散化处理逻辑函数又称sigmoid函数表达式为。y frac11et。该函数能将infty infty的值压缩到0 1区间通过选取合适的阈值转换为两个离散值大于05为1小于05为0。 3 朴素贝叶斯分类', '1贝叶斯定理。贝叶斯定理描述为。PAB  fracPAPBAPB。其中PA和PB是A事件和B事件发生的概率这两个事件是独立的不相互影响的朴素的含义PAB称为条件概率表示B事件发生条件下A事件发生的概率PA也称为先验概率PAB也称为后验概率先验概率主要根据统计获得后验概率利用贝叶斯定理计算后并根据实际情况进行修正其公式推导过程。PAB PBPAB。PBA PAPBA。其中PAB称为联合概率指事件B发生的概率乘以事件A在事件B发生的条件下发生的概率因为PABPBA 所以有。PBPABPAPBA。两边同时除以PB则得到贝叶斯定理的表达式', '2什么是朴素贝叶斯分类。朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法朴素的含义为假设问题的特征变量都是相互独立地作用于决策变量的即问题的特征之间都是互不相关的', '3朴素贝叶斯分类的特点nan', '4什么时候使用朴素贝叶斯。 根据先验概率计算后验概率的情况且样本特征之间独立性较强。 4 决策树分类。决策树分类和决策树回归思想基本相同不同的是决策树分类器输出为离散值通过决策树进行分支处理最后落到叶子节点上使用投票的方式来决定预测结果属于哪个类别。 5 支持向量机', '1什么是支持向量机。支持向量机Support Vector Machines是一种二分类模型它的目的是寻找一个超平面来对样本进行分割分割的原则是间隔最大化所谓支持向量就是下图中虚线穿过的边缘点支持向量机就对应着能将数据正确划分并且间隔最大的直线下图中红色直线。img支持向量png', '2SVM寻找最优边界要求有哪些。SVM寻找最优边界时需满足以下几个要求。1正确性对大部分样本都可以正确划分类别。2安全性支持向量即离分类边界最近的样本之间的距离最远。3公平性支持向量与分类边界的距离相等。4简单性采用线性方程直线平面表示分类边界也称分割超平面如果在原始维度中无法做线性划分那么就通过升维变换在更高维度空间寻求线性分割超平面 从低纬度空间到高纬度空间的变换通过核函数进行', '3什么是线性可分与线性不可分nan', '4什么是核函数。核函数用来对原还是进行升维和特征变换处理使得低纬度线性不可分问题变维高纬度线性可分问题常用的核函数有。 线性核函数表达式kxyxTyc 线性核函数是原始输入空间的内积即特征空间和输入空间的维度是一样的参数较少运算速度较快一般情况下在特征数量相对于样本数量非常多时适合采用线性核函数。 多项式核函数多项式核函数Polynomial Kernel用增加高次项特征的方法做升维变换当多项式阶数高时复杂度会很高其表达式为。KxyαxTycd。其中α表示调节参数d表示最高次项次数c为可选常数。 径向基核函数径向基核函数Radial Basis Function Kernel具有很强的灵活性应用很广泛与多项式核函数相比它的参数少因此大多数情况下都有比较好的性能在不确定用哪种核函数时可优先验证高斯核函数', '5SVM的特点nan', '1什么是聚类问题。聚类是指根据数据本身的特征将样本按照相似度距离相近划分为不同的类簇从而揭示样本之间内在的性质以及相互之间的联系规律聚类属于无监督学习', '2好的聚类算法有哪些特征。 良好的可伸缩性不仅能在小数据集上拥有良好性能得到较好聚类结果而且在处理大数据集时同样有较好的表现。 处理不同类型数据的能力不仅能够对数值型的数据进行聚类也能够对诸如图像文档序列等复杂数据进行聚类甚至在多种类型的混合数据集中有良好的表现。 处理噪声数据的能力实际应用中数据集的质量往往不理想包含很多噪声数据一个良好的聚类算法降低噪声数据对聚类结果的影响在低质量数据集中同样能够得到不错的聚类结果。 对样本顺序的不敏感性良好的聚类算法应当不受输入数据顺序的影响任意顺序数据输入都能够得到相同的聚类结果。 约束条件下的表现实际应用场景中聚类算法需要受到应用背景的约束良好的聚类算法在约束条件下同样能够对数据集进行良好的聚类并且得到高质量聚类结果。 易解释性和易用性不是所有的聚类分析使用者都是数据分析专家对于用户来说聚类分析算法应该方便使用且聚类得到的结果容易解释', '3聚类模型如何评价。理想的聚类可以用四个字概况内密外疏即同一聚类内部足够紧密聚类之间足够疏远 学科中使用轮廓系数来进行度量见下图。img轮廓系数jpg。假设我们已经通过一定算法将待分类数据进行了聚类常用的比如使用Kmeans将待分类数据分为了 k 个簇 对于簇中的每个向量分别计算它们的轮廓系数对于其中的一个点 i 来说。ai  averagei向量到所有它属于的簇中其它点的距离。bi  min i向量到各个非本身所在簇的所有点的平均距离。那么 i 向量轮廓系数就为。Sifracbiaimaxbi ai。由公式可以得出。1当biai时Si越接近于1这种情况聚类效果最好。2当biai时Si越接近于1这种情况聚类效果最差。3当biai时Si的值为0这种情况聚类出现了重叠。 2 KMeans聚类', '1什么是KMeans聚类。K均值聚类算法kmeans clustering algorithm是一种常用的聚类算法简单高效其步骤为。第一步根据事先已知的聚类数随机选择若干样本作为聚类中心计算每个样本与每个聚类中心的欧式距离离哪个聚类中心近就算哪个聚类中心的聚类完成一次聚类划分。第二步计算每个聚类的集合中心平均值如果几何中心与聚类中心不重合再以几何中心作为新的聚类中心重新划分聚类 重复以上过程直到某一次聚类划分后所得到的各个几何中心与其所依据的聚类中心重合或足够接近为止', '2KMeans的特点nan', '1什么是均值漂移。均值漂移是一种基于聚类中心的聚类算法其核心思想是在数据集中选定一个点然后以这个点为圆心r为半径画一个圆二维下是圆这里可以推广为高维圆求出这个点到所有点的向量的平均值而圆心与向量均值的和为新的圆心然后迭代此过程直到满足一点的条件结束。在实际计算时首先随便选择一个中心点然后计算该中心点一定范围之内所有点到中心点的距离向量的平均值计算该平均值得到一个偏移均值然后将中心点移动到偏移均值位置通过这种不断重复的移动可以使中心点逐步逼近到最佳位置这种思想类似于梯度下降方法通过不断的往梯度下降的方向移动可以到达梯度上的局部最优解或全局最优解。img均值向量与均值移动png。centerfont size2均值向量左与均值移动右示意图fontcenter', '2均值漂移算法特点nan', '1什么是噪声密度。噪声密度DensityBased Spatial Clustering of Applications with Noise 简写DBSCAN随机选择一个样本做圆心以事先给定的半径做圆凡被该圆圈中的样本都被划为与圆心样本同处一个聚类再以这些被圈中的样本做圆心以事先给定的半径继续做圆不断加入新的样本扩大聚类的规模知道再无新的样本加入为止即完成一个聚类的划分 以同样的方法在其余样本中继续划分新的聚类直到样本空间被耗尽为止即完成整个聚类划分过程。imgDBSCAN示意图png。 边界点Border point所处聚类中样本数少于某个阈值该聚类就不被视为一个聚类其中的样本则称为边界点。 噪声点Noise无法划分到某个聚类中的点。 核心点Core point除了孤立样本和外周样本以外的样本都是核心点', '2DBSCAN的特点nan', '1什么是凝聚层次。凝聚层次Agglomerative算法首先将每个样本看做独立的聚类如果聚类数大于预期则从每个样本出发凝聚离它最近的样本将样本凝聚所形成的团块作为新的聚类再不断扩大聚类规模的同时减少聚类的总数直到聚类数减少到预期值为止  这里的关键问题是如何计算聚类之间的距离。依据对距离的不同定义将Agglomerative Clustering的聚类方法分为三种。 ward默认选项挑选两个簇来合并是的所有簇中的方差增加最小这通常会得到大小差不多相等的簇。 average链接将簇中所有点之间平均距离最小的两个簇合并。 complete链接也称为最大链接将簇中点之间最大距离最小的两个簇合并。ward适用于大多数数据集如果簇中的成员个数非常不同比如其中一个比其他所有都大得多那么average或complete可能效果更好', '2凝聚层次特点nan', '1 什么是前馈神经网络。前馈神经网络feedforward neural network又称多层感知机multilayer perceptron  MLP是典型的深度学习模型它是一种单向多层结构其中每一层包含若干个神经元在此种神经网络中各神经元可以接收前一层神经元的信号并产生输出到下一层第0层叫输入层最后一层叫输出层其他中间层叫做隐含层或隐藏层隐层隐含层可以是一层也可以是多层整个网络中无反馈信号从输入层向输出层单向传播可用一个有向无环图表示。深度神经网络img前馈神经网络png。前馈神经网络使用数学公式可以表示为。fx  f3f2f1x。其中f1 被称为网络的 第一层first layer f2 被称为 第二层second layer以此类推链的全长称为模型的深度depth', '2 深度学习有什么优缺点。1优点。 性能更优异。 不需要特征工程。 在大数据样本下有更好的性能。 能解决某些传统机器学习无法解决的问题。2缺点。 小数据样本下性能不如机器学习。 模型复杂。 过程不可解释', '3 什么是激活函数为什么要使用激活函数。激活函数activation function指神经网络中将输入信号的总和转换为输出信号的函数激活函数将多层感知机输出转换为非线性使得神经网络可以任意逼近任何非线性函数这样神经网络就可以应用到众多的非线性模型中', '4 神经网络中常用的激活函数有哪些各自有什么特点。1sigmoid。① 定义sigmoid函数也叫Logistic函数用于隐层神经元输出能将inftyinfty的数值映射到01的区间可以用来做二分类表达式为。fx  frac11ex。② 特点。 优点平滑易于求导。 缺点激活函数计算量大反向传播求误差梯度时求导涉及除法反向传播时很容易就会出现梯度消失。2tanh。① 定义双曲正切函数表达式为。fx  frac1e2x1e2x。② 特点。 优点平滑易于求导输出均值为0收敛速度要比sigmoid快从而可以减少迭代次数。 缺点很容易就会出现梯度消失。3relu。① 定义修正线性单元其表达式为。fx begincases。x  x0 。0  x0。endcases。② 特点。 优点计算过程简单避免了梯度爆炸和梯度消失问题。 缺点小于等于0时无输出', '5 什么是softmax函数其主要作用是什么。1定义Softmax函数就可以将多分类的输出数值转化为相对概率而这些值的累和为1表达式为。S_i  fraceV_isum_iCeV_i。其中V_i 是分类器前级输出单元的输出i 表示类别索引总的类别个数为 CS_i表示的是当前元素的指数与所有元素指数和的比值。2作用softmax一般用于分类输出层计算属于每个类别的概率', '6 什么是损失函数损失函数的作用是什么。损失函数Loss Function也有称之为代价函数Cost Function用来度量预测值和实际值之间的差异从而作为模型性能参考依据损失函数值越小说明预测输出和实际结果也称期望输出之间的差值就越小也就说明我们构建的模型越好反之说明模型越差', '7 什么是交叉熵其作用是什么。交叉熵Cross Entropy主要用于度量两个概率分布间的差异性信息在机器学习中用来作为分类问题的损失函数当预测概率越接近真实概率该函数值越小反之越大', '8 解释什么是梯度。梯度gradient是一个向量表示某一函数在该点处的方向导数沿着该方向取得最大值即函数在该点处沿着该方向此梯度的方向变化最快变化率最大', '9 什么是梯度下降。梯度下降是一个最优化算法常用于机器学习和人工智能当中用来递归性地逼近最小偏差模型核心思想是按照梯度相反的方向不停地调整函数权值其步骤为。1求损失函数值。2损失是否足够小如果不是计算损失函数的梯度。3按梯度的反方向走一小步调整权重w_i  w_i  delta w_i。4循环到第2步迭代执行', '10 激活函数出现梯度消失会有什么后果。机器学习中如果模型的优化依赖于梯度下降梯度消失会导致模型无法进一步进行优化', '11 如何解决梯度消失问题重点。1更换激活函数如更滑为relu leakrelu。2批量规范化处理通过规范化操作将输出信号x规范化到均值为0方差为1保证网络的稳定性。3使用残差结构通过引入残差结构能有效避免梯度消失问题', '12 什么是梯度爆炸如何解决梯度爆炸问题。1梯度爆炸梯度消失是在计算中出现了梯度过小的值梯度爆炸则相反梯度计算出现了过大的值梯度过大可能使参数更新幅度过大超出了合理范围。2解决梯度爆炸的方法。 梯度裁剪把沿梯度下降方向的步长限制在一个范围之内计算出来的梯度的步长的范数大于这个阈值的话就以这个范数为基准做归一化使这个新的的梯度的范数等于这个阈值。 权重正则化通过正则化可以部分限制梯度爆炸的发生', '13 什么是批量梯度下降随机梯度下降分别有何特点nan', '1批量梯度下降。① 定义批量梯度下降Batch Gradient DescentBGD是指在每一次迭代时使用所有样本来进行梯度的更新。② 特点。 优点收敛比较稳定。 缺点当样本数目很大时每迭代一步都需要对所有样本计算训练过程会很慢', '2随机梯度下降。① 定义随机梯度下降法Stochastic Gradient DescentSGD每次迭代使用一个样本来对参数进行更新使得训练速度加快。② 特点。 优点计算量小每一轮训练更新速度快。 缺点收敛不稳定', '14 什么是学习率作用是什么。在梯度下降法中都是给定的统一的学习率整个优化过程中都以确定的步长进行更新 在迭代优化的前期中学习率较大则前进的步长就会较长这时便能以较快的速度进行梯度下降而在迭代优化的后期逐步减小学习率的值减小步长这样将有助于算法的收敛更容易接近最优解', '15 学习率过大或过小会导致什么问题。学习率过大可能导致模型无法收敛过小导致收敛速度过慢', '16 什么是反向传播算法为什么要使用反向传播算法。1定义。反向传播Backpropagation algorithm全称误差反向传播是在深度神经网络中根据输出层输出值来反向调整隐藏层权重的一种方法。2对于多个隐藏层的神经网络输出层可以直接求出误差来更新参数但隐藏层的误差是不存在的因此不能对它直接应用梯度下降而是先将误差反向传播至隐藏层然后再应用梯度下降', '17 请说明MomentumAdaGradAdam梯度下降法的特点。MomentumAdaGradAdam是针对SGD梯度下降算法的缺点的改进算法在SGD算法中如果函数的形状非均向参数大小差异较大SGD的搜索路径会呈之字形移动搜索效率较低如下图所示。SGD路径imgSGD路径png', '1Momentum。Momentum是动量的意思和物理有关用数学式表示Momentum方法如下所示。v  alpha v  eta fracpartial Lpartial W 。W  W  v。其中W表示要更新的权重参数fracpartial Lpartial W表示W的梯度eta表示学习率v对应物理上的速度在物体不受任何力时该项承担使物体逐渐减速的任务α设定为09之类的值对应物理上的地面摩擦或空气阻力和SGD相比我们发现之字形的程度减轻了这是因为虽然x轴方向上受到的力非常小但是一直在同一方向上受力所以朝同一个方向会有一定的加速反过来虽然y轴方向上受到的力很大但是因为交互地受到正方向和反方向的力它们会互相抵消所以y轴方向上的速度不稳定因此和SGD时的情形相比可以更快地朝x轴方向靠近减弱之字形的变动程度如下图所示。Momentum路径imgMomentum路径png', '2AdaGrad。AdaGrad会为参数的每个元素适当地调整学习率与此同时进行学习AdaGrad的Ada来自英文单词Adaptive即适当的的意思其表达式为。h  h  fracpartial L partial W bigodot fracpartial L partial W 。W  W  eta frac1sqrt h fracpartial Lpartial W。其中W表示要更新的权重参数fracpartial Lpartial W表示W的梯度eta表示学习率fracpartial L partial W bigodot fracpartial L partial W表示所有梯度值的平方和在参数更新时通过乘以frac1sqrt h就可以调整学习的尺度这意味着参数的元素中变动较大被大幅更新的元素的学习率将变小也就是说可以按参数的元素进行学习率衰减使变动大的参数的学习率逐渐减小其收敛路径如下图所示。AdaGrad路径imgAdaGrad路径png', '3Adam。Adam是2015年提出的新方法它的理论有些复杂直观地讲就是融合了Momentum和AdaGrad的方法通过组合前面两个方法的优点有望实现参数空间的高效搜索其收敛路径如下图所示。Adam路径imgAdam路径png。以下是几种梯度下降算法的收敛情况对比。AdaAdamMomSGD对比imgAdaAdamMomSGD对比png', '18 什么是卷积函数。卷积函数指一个函数和另一个函数在某个维度上的加权叠加作用其表达式为。st  int infty_inftyfagtada。离散化卷积函数表示为。st ftgt sum_ninftyinftyfagta。', '19 二维卷积运算中输出矩阵大小与输入矩阵卷积核大小步幅填充的关系。OH  fracH2PFHS  1 。OW  fracW2PFWS  1。', '20 什么是池化池化层的作用是什么。也称子采样层或下采样层Subsampling Layer目的是缩小高长方向上的空间的运算以降低计算量提高泛化能力', '21 什么是最大池化平均池化。最大池化取池化区域内的最大值作为池化输出。平均池化取池化区域内的平均值作为池化输出', '22 池化层有什么特征。1没有要学习的参数。2通道数不发生变化。3对微小的变化具有鲁棒性', '23 什么是归一化 为什么要进行归一化。1归一化的含义归一化是指归纳统一样本的统计分布性归一化在  01 之间是统计的概率分布归一化在 11 之间是统计的坐标分布。2归一化处理的目的。 为了后面数据处理的方便归一化的确可以避免一些不必要的数值问题。 为了程序运行时收敛加快。 同一量纲样本数据的评价标准不一样需要对其量纲化统一评价标准。 避免神经元饱和当神经元的激活在接近 0 或者 1 时会饱和在这些区域梯度几乎为 0这样在反向传播过程中局部梯度就会接近 0这会有效地杀死梯度', '24 什么是批量归一化其优点是什么。1批量归一化Batch Normalization简写BN指在神经网络中间层也进行归一化处理使训练效果更好的方法就是批归一化。2优点。 减少了人为选择参数在某些情况下可以取消 dropout 和 L2 正则项参数或者采取更小的 L2 正则项约束参数。 减少了对学习率的要求现在我们可以使用初始很大的学习率或者选择了较小的学习率算法也能够快速训练收敛。 可以不再使用局部响应归一化BN 本身就是归一化网络 。 破坏原来的数据分布一定程度上缓解过拟合。 减少梯度消失加快收敛速度提高训练精度', '25 请列举AlexNet的特点。 使用ReLU作为激活函数并验证其效果在较深的网络超过了Sigmoid成功解决了Sigmoid在网络较深时的梯度消失问题。 使用Dropout丢弃学习随机忽略一部分神经元防止过拟合。 在CNN中使用重叠的最大池化此前CNN中普遍使用平均池化AlexNet全部使用最大池化避免平均池化的模糊化效果。 提出了LRNLocal Response Normalization局部正规化层对局部神经元的活动创建竞争机制使得其中响应比较大的值变得相对更大并抑制其他反馈较小的神经元增强了模型的泛化能力。 使用CUDA加速深度卷积网络的训练利用GPU强大的并行计算能力处理神经网络训练时大量的矩阵运算。 26 什么是dropout操作dropout的工作原理', '1dropout定义。Dropout是用于深度神经网络防止过拟合的一种方式在神经网络训练过程中通过忽略一定比例的特征检测器让一半的隐层节点值为0可以明显地减少过拟合现象这种方式可以减少特征检测器隐层节点间的相互作用检测器相互作用是指某些检测器依赖其他检测器才能发挥作用简单来说在前向传播的时候让某个神经元的激活值以一定的概率p停止工作这样可以使模型泛化性更强因为它不会太依赖某些局部的特征', '2dropout工作原理。假设我们要训练这样一个网络结构如下图所示。standard_cnnimgstandard_cnnpng。输入是x输出是y正常的流程是我们首先把x通过网络前向传播然后把误差反向传播以决定如何更新参数让网络进行学习使用Dropout之后过程变成如下。standard_cnn_dropoutimgstandard_cnn_dropoutpng。1首先随机临时删掉网络中一半的隐藏神经元输入输出神经元保持不变上图中虚线表示临时被删除的神经元。2 然后把输入x通过修改后的网络前向传播然后把得到的损失结果通过修改的网络反向传播一小批训练样本执行完这个过程后在没有被删除的神经元上按照随机梯度下降法更新对应的参数wb。3然后继续重复以下过程。 恢复被删掉的神经元此时被删除的神经元保持原样而没有被删除的神经元已经有所更新。 从隐藏层神经元中随机选择一定比率子集临时删除掉备份被删除神经元的参数。 对一小批训练样本先前向传播然后反向传播损失并根据随机梯度下降法更新参数wb 没有被删除的那一部分参数得到更新删除的神经元参数保持被删除前的结果', '3为什么dropout能避免过拟合。1取平均作用不同的网络可能产生不同的过拟合取平均则有可能让一些相反的拟合互相抵消。2减少神经元之间复杂的共适应关系因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现这样权值的更新不再依赖于有固定关系的隐含节点的共同作用阻止了某些特征仅仅在其它特定特征下才有效果的情况 迫使网络去学习更加鲁棒的特征 这些特征在其它的神经元的随机子集中也存在', '27 卷积层和池化层有什么区别。卷积层核池化层在结构上具有一定的相似性都是对感受域内的特征进行提取并且根据步长设置获取到不同维度的输出但是其内在操作是有本质区别的如下表所示。                             卷积层                               池化层              。      。  结构                 通道数改变                 通常特征维度会降低通道数不变  。 稳定性  输入特征发生细微改变时输出结果会改变  感受域内的细微变化不影响输出结果 。  作用          感受域内提取局部关联特征          感受域内提取泛化特征降低维度  。 参数量       与卷积核尺寸卷积核个数相关                不引入额外参数          ', '28 如何选择卷积核大小。在早期的卷积神经网络中如LeNet5AlexNet用到了一些较大的卷积核11times11受限于当时的计算能力和模型结构的设计无法将网络叠加得很深因此卷积网络中的卷积层需要设置较大的卷积核以获取更大的感受域但是这种大卷积核反而会导致计算量大幅增加不利于训练更深层的模型相应的计算性能也会降低后来的卷积神经网络VGGGoogLeNet等发现通过堆叠2个3times 3卷积核可以获得与5times 5卷积核相同的感受视野同时参数量会更少3321   55113times 3卷积核被广泛应用在许多卷积神经网络中因此可以认为在大多数情况下通过堆叠较小的卷积核比直接采用单个更大的卷积核会更加有效', '29 如何提高图像分类的准确率。1样本优化。 增大样本数量。 数据增强形态色彩噪声扰动。2参数优化。 批量正则化。 变化学习率。 权重衰减。3模型优化。 增加网络模型深度。 更换更复杂的模型。 自然语言处理。 一基本理论。 1', '1 什么是分词分词的作用是什么。该任务将文本语料库分隔成原子单元例如单词或词组分词是自然语言处理的一项重要任务直接关系到对语义的正确理解', '2 中文分词有哪些方法nan', '3 什么是词性标记。词性标记PartOfSpeech tagging POS tagging是将单词分配到各自对应词性的任务它既可以是名词动词形容词副词介词等基本词也可以是专有名词普通名词短语动词动词等', '4 什么是词干提取。词干提取stemming是抽取词的词干或词根形式不一定能够表达完整语义文本样本中的单词的词性与时态对于语义分析并无太大影响所以需要对单词进行词干提取', '5 词干提取主要有哪些方法。1查找算法一个简单的词干提取器从查找表中查找词尾变化这种方法的优势是简单速度快并容易控制异常情况但它的缺点是所有的词尾变化的形式必须明确地包含在查询表中一个新的或者是陌生的词是没办法控制的即使是具有完整的规则如iPads  iPad并且表会变得非常大对于具有简单形态的语言像英文表的大小比较适中但对于变化较大语言如土耳其语对于每个词根都可能有几百个潜在的变化形式 一个查找算法初步词性标注来避免过度词干化。2后缀去除法后缀去除算法不依赖于包含词形变换和词根的查询表而是使用一个普遍性规则小列表提取词根形式如其中的一些规则包括去掉结尾是edingly等后缀。3lemmatization算法一种更加复杂的确定一个词汇停顿词的方法是lemmatisation这种处理方式包括首先确定词汇的发音部分接着根据发音的部分确定词汇的根停顿词规则随着单词的发声部分的改变而改变。4混合法混合方法同时使用上述的方法中的两种或更多种', '6 什么是词形还原。词形还原就是去掉单词的词缀提取单词的主干部分通常提取后的单词会是字典中的单词不同于词干提取stemming提取后的单词不一定会出现在单词中词形还原是基于词典将单词的复杂形态转变成最基础的形态词形还原不是简单地将前后缀去掉而是会根据词典将单词进行转换比如drove会转换为drive词形还原可以将复数还原为单数也可将带时态的分词还原为原型', '7 什么是词袋模型词袋模型的缺点是什么。词袋模型Bagofwords model简称 BoW 假设我们不考虑文本中词与词之间的上下文关系一句话的语义很大程度取决于某个单词出现的次数所以可以把句子中所有可能出现的单词作为特征名每一个句子为一个样本单词在句子中出现的次数为特征值构建数学模型称为词袋模型可以理解为用词频作为每个样本的特征。词袋模型仅仅考虑了词频没有考虑上下文的关系即词语间的顺序因此会丢失一部分文本的语义', '8 什么是词频文档频率逆文档频率nan', '9 什么是词频逆文档频率TFIDF。词频逆文档频率Term Frequency  Inverse Document Frequency指词频矩阵中的每一个元素乘以相应单词的逆文档频率。TFIDF  TF  IDF。其值越大说明该词对样本语义的贡献越大根据每个词的贡献力度构建学习模型如果某个词或短语在一篇文章中出现的频率TF高并且在其他文章中很少出现则认为此词或者短语具有很好的类别区分能力适合用来分类', '10 文本表示如何采用独热编码其缺点是什么。1独热编码把每个词表示为一个长向量这个向量的维度是词表大小向量中只有一个维度的值为1其余维度为0这个维度就代表了当前的词例如。python。减肥 1000000000。瘦身 0100000000。减脂 0010000000。降脂 0001000000。增肥 0000100000。2独热编码的缺点。 丢弃了词与词之间的联系无法反映出词的距离关系。 独热编码产生一个高纬度稀疏矩阵会导致特征空间非常大', '11 什么是Ngram模型。1定义NGram模型是一种基于统计语言模型语言模型是一个基于概率的判别模型它的输入是个句子由词构成的顺序序列输出是这句话的概率即这些单词的联合概率。NGram本身也指一个由N个单词组成的集合各单词具有先后顺序且不要求单词之间互不相同常用的有BigramN2和TrigramN3例如。句子L love deep learning。Bigram I love love deep deep learning。Trigram I love deep love deep learning。2基本思想NGram基本思想是将文本里面的内容按照字节进行大小为n的滑动窗口操作形成了长度是n的字节片段序列每一个字节片段称为一个gram对所有gram的出现频度进行统计并按照事先设置好的频度阈值进行过滤形成关键gram列表也就是这个文本向量的特征空间列表中的每一种gram就是一个特征向量维度。 12 语料库', '1什么是语料库。语料库corpus是指存放语言材料的仓库现代的语料库是指存放在计算机里的原始语料文本或经过加工后带有语言学信息标注的语料文本以语言的真实材料为基础来呈现语言知识反映语言单位的用法和意义基本以知识的原型形态表现语言的原貌', '2语料库的特征。 语料库中存放的是实际中真实出现过的语言材料。 语料库是以计算机为载体承载语言知识的基础资源但不等于语言知识。 真实语料需要经过分析处理和加工才能成为有用的资源', '3语料库的作用。 支持语言学研究和语言教学研究。 支持NLP系统的开发', '4语料库的类型nan', '13 什么是共现矩阵特点是什么。1共现cooccurrence矩阵指通过统计一个事先指定大小的窗口内的word共现次数以word周边的共现词的次数做为当前word的vector具体来说我们通过从大量的语料文本中构建一个共现矩阵来定义word representation例如有语料如下。I like deep learning。I like NLP。I enjoy flying。则其共现矩阵如下。img词的共现矩阵png。2特点。 优点矩阵定义的词向量在一定程度上缓解了onehot向量相似度为0的问题。 缺点但没有解决数据稀疏性和维度灾难的问题。14  Word2vec', '1什么是Word2vec。Word2vec是最近推出的分布式单词表示学习技术目前被用作许多NLP任务的特征工程技术例如机器翻译聊天机器人和图像标题生成从本质上讲Word2vec通过查看所使用的单词的周围单词即上下文来学习单词表示更具体地说我们试图通过神经网络根据给定的一些单词来预测上下文单词反之亦然这使得神经网络被迫学习良好的词嵌入。Word2vec通过查看单词上下文并以数字方式表示它来学习给定单词的含义所谓上下文指的是在感兴趣的单词的前面和后面的固定数量的单词假设我们有一个包含N个单词的语料库在数学上这可以由以w_0w_1  w_i和w_N表示的一系列单词表示其中w_i是语料库中的第i个单词。如果我们想找到一个能够学习单词含义的好算法那么在给定一个单词之后我们的算法应该能够正确地预测上下文单词这意味着对于任何给定的单词wi以下概率应该较高。word2vec表达式imgword2vec表达式png。为了得到等式右边我们需要假设给定目标单词wi的上下文单词彼此独立例如wi2和wi1是独立的虽然不完全正确但这种近似使得学习问题切合实际并且在实际中效果良好', '2Word2vec的优点。 Word2vec方法并不像基于WordNet的方法那样对于人类语言知识具有主观性。 与独热编码表示或单词共现矩阵不同Word2vec表示向量大小与词汇量大小无关。 Word2vec是一种分布式表示与表示向量取决于单个元素的激活状态的例如独热编码局部表示不同分布式表示取决于向量中所有元素的激活状态这为Word2vec提供了比独热编码表示更强的表达能力', '3示例。考虑以下非常小的文本。python。There was a very rich king He had a beautiful queen She was very kind。做一些预处理并删除标点符号和无信息的单词。python。was rich king he had beautiful queen she was kind。现在让我们用其上下文单词为每个单词形成一组元组其格式为目标单词上下文单词1上下文单词2目标是给出左侧的单词能够预测右侧的单词我们假设两边的上下文窗口大小为1。was  rich。rich  was king。king  rick he。he  king had。had  he beautiful。beautiful  had queen。she  queen was。was  she kind。kind  was。表示成词向量如下所示。词向量img词向量png。可以得到如下推导。python。queen  king  he  she。 0 08  05 08  05 06。 0 06。对于现实世界的语料库来说这是一个不切实际的缩小规模之后的练习因此仅仅通过处理十几个数字是无法手工计算出这些词向量的值的这是复杂的函数逼近方法如神经网络为我们做的那样实际任务中词汇量也很容易超过10000个单词因此我们不能手动为大型文本语料库开发词向量而需要设计一种方法来使用一些机器学习算法例如神经网络自动找到好的词嵌入以便有效地执行这项繁重的任务。 计算机视觉。 一基本理论。 1', '1 什么是图像采样。采样是按照某种时间间隔或空间间隔将空间上连续的图像变换成离散点的操作称为图像采样', '2 什么是分图像辨率。采样后得到离散图像的尺寸称为图像分辨率分辨率是数字图像可辨别的最小细节分辨率由宽width和高height两个参数构成宽表示水平方向的细节数高表示垂直方向的细节数例如一副640480分辨率的图像表示这幅图像是由 640480307200个点组成一副19201080分辨率的图像表示这幅图像是由19201080 2073600个点组成', '3 什么是RGB颜色空间。RGB颜色空间中每个像素点有三个维度分别记录在红Red绿Green蓝Blue三原色的分量上的亮度', '4 什么是HSV颜色空间。HSV颜色空间是另一种常用的计算机中表示颜色的方法HSV表示色相hue饱和度saturation和亮度valueH表示颜色的相位角hue 取值范围是0360S表示颜色的饱和度saturation 范围从0到1它表示成所选颜色的纯度和该颜色最大的纯度之间的比率V表示色彩的明亮程度value 范围从0到1。HSVimgHSVpng', '5 什么是图像灰度化处理。在RGB模型中如果RGB时则彩色表示一种灰度颜色其中RGB的值叫灰度值因此灰度图像每个像素只需一个字节存放灰度值又称强度值亮度值灰度范围为0255将RGB图像转换为灰度图像的过程称为图像灰度化处理', '6 图像灰度化处理有哪些方法。1分量法将彩色图像中的三分量的亮度作为三个灰度图像的灰度值可根据应用需要选取一种灰度图像。2最大值法将彩色图像中的三分量亮度的最大值作为灰度图的灰度值。3将彩色图像中的三分量亮度求平均得到一个灰度值。4根据重要性及其它指标将三个分量以不同的权值进行加权平均例如由于人眼对绿色的敏感最高对蓝色敏感最低因此按下式对RGB三分量进行加权平均能得到较合理的灰度图像。fij030Rij059Gij011Bij。', '7 图像加法运算有什么应用。1图像加法可以用于多幅图像平均去除噪声如下图。图像加法img图像加法png。2图像加法实现水印的叠加效果', '8 图像减法运算有什么应用。主要意义是增强图像间的差别图像减法在连续图像中可以实现消除背景和运动检测如下图。img图像减法png', '9 图像放大时可以采用哪些插值法。1最邻近插值法最邻近插值法使用点x y最近的整数坐标处的灰度值作为xy的值这种插值方法计算量小但精度不高并且可能破坏图像中的线性关系。2双线性插值法双线性插值法使用点x y最邻近的4个像素值进行插值计算在两个方向上执行两次线性插值操作', '10 什么是直方图均衡化。直方图均衡化将原始图像的直方图即灰度概率分布图进行调整使之变化为均衡分布的样式达到灰度级均衡的效果可以有效增强图像的整体对比度。直方图均衡化能够自动的计算变化函数通过该方法自适应得产生有均衡直方图的输出图像能够对图像过暗过亮和细节不清晰的图像得到有效的增强。直方图均衡化img直方图均衡化png', '11 什么是均值滤波。均值滤波指模板权重都为1的滤波器它将像素的邻域平均值作为输出结果均值滤波可以起到图像平滑的效果可以去除噪声但随着模板尺寸的增加图像会变得更为模糊经常被作为模糊化使用。均值滤波img均值滤波png', '12 什么是高斯滤波。为了减少模板尺寸增加对图像的模糊化可以使用高斯滤波器高斯滤波的模板根据高斯分布来确定模板系数接近中心的权重比边缘的大大小为5的高斯滤波器及滤波效果如下所示。高斯滤波img高斯滤波png', '13 什么是图像二值化处理有什么优点。1图像二值化Image Binarization就是将图像上的像素点的灰度值全部设置为黑色0或白色255也就是将整个图像分割成明显的黑白效果的过程二值化的方法是通过设定一个阈值大于阈值部分全部置成255小于阈值部分全部置成0。2优点。 二值图像在数字图像处理中占有非常重要的地位可以方便得进行连通域提取形态学变化感兴趣区域分割等操作。 图像的二值化使图像中数据量大为减少并且能突显出目标的轮廓二值化后的图像的集合性质只与像素值为0或255的点的位置有关不再涉及像素的多级值使处理变得简单而且计算过程中数据的处理量减小', '14 什么是图像膨胀。图像膨胀dilate是指根据原图像的形状向外进行扩充。图像膨胀img图像膨胀png', '15 什么是图像腐蚀。图像腐蚀erode是指根据原图像的形状向内进行收缩。图像腐蚀img图像腐蚀png', '16 什么是图像开运算。开运算就是先腐蚀再膨胀开运算能够把比结构元素小的噪声和突刺过滤掉并切断细长的连接起到分离的作用例如将因噪声影响粘连在一起的区域分割开来。图像开运算img图像开运算png', '17 什么是图像闭运算。闭运算就是先膨胀再腐蚀闭运算可以把比结构元素小的缺憾或者空洞补上将细小断裂的区域进行连通例如将因图像质量而断裂的目标区域进行合并连通。图像闭运算img图像闭运算png', '18 什么是仿射变换。仿射变换是指图像可以通过一系列的几何变换来实现平移旋转等多种操作该变换能够保持图像的平直性和平行性平直性是指图像经过仿射变换后直线仍然是直线平行性是指图像在完成仿射变换后平行线仍然是平行线。图像仿射变换img图像仿射变换png', '19 什么是礼帽运算。礼帽运算是用原始图像减去其开运算图像的操作礼帽运算能够获取图像的噪声信息或者得到比原始图像的边缘更亮的边缘信息。图像礼帽运算img图像礼帽运算png', '20 什么是图像黑帽运算。黑帽运算是用闭运算图像减去原始图像的操作黑帽运算能够获取图像内部的小孔或前景色中的小黑点或者得到比原始图像的边缘更暗的边缘部分。图像礼帽运算img图像黑帽运算png', '21 什么是图像金字塔。图像金字塔是由一幅图像的多个不同分辨率的子图所构成的图像集合该组图像是由单个图像通过不断地降采样所产生的最小的图像可能仅仅有一个像素点通常情况下图像金字塔的底部是待处理的高分辨率图像原始图像而顶部则为其低分辨率的近似图像向金字塔的顶部移动时图像的尺寸和分辨率都不断地降低通常情况下每向上移动一级图像的宽和高都降低为原来的二分之一。图像金子塔可以得到大小不同的图像从而更方便进行图像处理计算识别以及特征提取。图像金子塔1img图像金子塔1png。图像金字塔img图像金字塔png', '22 什么是霍夫变换。霍夫变换是一种在图像中寻找直线圆形以及其他简单形状的方法霍夫变换采用类似于投票的方式来获取当前图像内的形状集合该变换由Paul Hough霍夫于1962年首次提出最初的霍夫变换只能用于检测直线经过发展后霍夫变换不仅能够识别直线还能识别其他简单的图形结构常见的有圆椭圆等。霍夫变换2img霍夫变换2png。 企业真题。 1', '1填空题。在SVM逻辑回归等二分类模型中在模型训练完成后如果调高分类阈值会导致模型的精准率precision提高模型的召回率recall降低模型的aucArea Under Curve不变', '2填空题。在模型训练过程中一般情况下增加batch size会导致模型的收敛速度变慢减少学习率步长会导致模型的收敛速度变慢', '3填空题。LSTM对比原始RNN的最大改进是解决了梯度消失能处理更长的序列biLSTM对比LSTM最大的改进是能够提取反向序列特征', '4问答题用户的年龄是离散特征还是连续特征在输入模型之前如何进行处理。答年龄是连续特征对连续特征处理有如下方式。 模型接收的特征为离散需要将年龄进行离散化处理按不同数值进行分段。 模型可以接收连续特征但要是用梯度下降法优化该种情况下需要对年龄进行归一化处理归一化到01之间例如神经网络模型。 模型可以接收连续特征但不需要梯度下降法优化该种情况下直接将年龄输入模型即可', '5问答题假如训练集正负样本比例为19准确率accuracy为90验证集测试集正负样本比例为11准确率为50能否肯定发生了过拟合现象如何解决上述问题。答该现象 为样本不均衡导致的欠拟合由于样本不均衡导致模型并没有学习到数据的真实分布规律解决方法是对多数样本进行降采样对少数样本进行升采样', '6问答题经过下列卷积操作后33 conv  33 conv  22  max pool  33 conv卷积步长为1没有填充输出神经元感受野是多大。答感受野大小计算公式为。RF_n  RF_n1  f_n  1 times prod_i1n1 s_i。其中RF_n表示第n层感受野大小RF_n1表示已经计算出的n1层感受野大小f_n表示第n层卷积核或池化区域大小s_i表示1到n1层卷积池化步长的连乘现将每层参数列入下表。 层数   卷积核  池化区域  步长 。      。 Conv1  33                1    。 Conv2  33                1    。 Pool3  22                2    。 Conv4  33                1    。根据公式上面卷积池化感受野大小为。RF_1  3 。RF_2  RF_1  31  1  3  2  5 。RF_3  RF_2  21  1  1  6 。RF_4  RF_3  31  1  2  1  10。', '7神经网络加速训练方法有哪些。答可以从多个层级对模型进行优化和加速。 硬件层使用GPU代替CPU训练使用多GPU代替单GPU训练。 模型层采用轻量级模型对模型进行裁剪知识蒸馏。 参数层采用归一化batch normal等方法。 代码层采用变化学习率开始时学习率调大训练一些轮次逐渐调小采用合适优化器例如自动应梯度下降优化器', '8解释一下BN层的作用并简述其公式含义。 BN的作用缓解梯度消失缓解过拟合加快模型收敛速度增加模型稳定性。 BN的计算公式。BNimgBNpng', '9写出SVM中的硬间隔分类的loss。答硬间隔指分类误差为0即所有的样本都分类正确软间隔指允许有一定程度的较小分类误差SVM损失函数的推导过程如下。svm_lossimgsvm_losspng。根据SVM正负例都在间隔上或间隔外样本需满足以下条件。fractheta  T xi  btheta ge d  yi  1 。fractheta  T xi  btheta le d  yi  1。不等式左右同时除以d得。fractheta  T xi  bthetad ge 1  yi  1 。fractheta  T xi  bthetad le 1  yi  1。上式中主要关注fractheta Tthetad和fracbthetad可以发现本质没有什么变化只是在原基础上进行了一定程度的缩放所以等式可简化为。theta  T xi  b ge 1  yi  1 。theta  T xi  b le 1  yi  1。综合上面两种情况将yi乘进去可以写成一个不等式。yitheta  T xi  b ge 1。同时可以通过计算求得支持向量到分类边界的间隔为。d  fracthetaTx btheta  frac1theta。所以要想获得最大间隔的SVM即要满足约束条件同时最大化几何间隔。maxfrac1theta 。st   yitheta T xi  b ge 1。', '10问答题TFIDF与DF相比优势是什么。答单词权重最为有效的实现方法就是TFIDF 其指导思想建立在这样一条基本假设之上 在一个文本中出现很多次的单词 在另一个同类文本中出现次数也会很多 反之亦然所以如果特征空间坐标系取TF 词频作为测度 就可以体现同类文本的特点另外还要考虑单词区别不同类别的能力 TFIDF 法认为一个单词出现的文本频率越小 它区别不同类别的能力就越大 所以引入了逆文本频度IDF 的概念 以TF 和IDF 的乘积作为特征空间坐标系的取值测度。文档频数Document Frequency DF是最为简单的一种特征选择算法它指的是在整个数据集中有多少个文本包含这个单词在训练文本集中对每个特征计一算它的文档频次并且根据预先设定的阑值去除那些文档频次特别低和特别高的特征', '11问答题对于中文LDANER和文本分类任务是字向量好一些还是词向量好一些为什么。答当使用机器学习的算法构建文本向量时如词袋模型TFIDF和Ngram模型时词向量算法会优于字向量因为这些算法本身不能表示单词的语言信息而机器学习算法通过分词后更能表达语句的含义所以词向量优于字向量。而采用深度学习算法构建文本向量时字向量优于词向量本质是指字向量在保持本身运算性能优越的同时语义上可以表达词向量等级的更细腻语义', '12简述离散化的好处并写出离散化的常用方法有哪些。 离散化的好处降维非线性化容易增加和减少特征降低噪声值的影响。 离散化的方法。 区间划分法如1100岁可以划分为018未成年1850中青年50100中老年区间划分包括等距划分按阶段划分特殊点划分等。 卡方检验分裂方法就是找到一个分裂点看左右2个区间在目标值上分布是否有显著差异有显著差异就分裂否则就忽略这个点可以每次找差异最大的点合并类似先划分如果很小单元区间按顺序合并在目标值上分布不显著的相邻区间直到收敛卡方值通常由χ2分布近似求得 χ2表示观察值与理论值之问的偏离程度。 信息增益法这个和决策树的学习很类似分裂方法就是找到一个分裂点看左右2个区间看分裂前后信息增益变化阈值如果差值超过阈值正值分列前分裂后信息熵则分裂每次找差值最大的点做分裂点直到收敛合并类似先划分如果很小单元区间按顺序合并信息增益小于阈值的相邻区间直到收敛', '13利用梯度下降法优化目标函数lnwx给定第一轮参数w2 x10请写出第三轮优化后的参数值学习率lambda  01。第一步根据初始值计算梯度。fracpartial ypartial w  lnw  lnx  lnw frac1w。所以w的初始梯度为 1  2  05。第二步根据梯度更新公式计算更新w。w  w  Delta w  2  01  05  195。第三步继续计算第二轮梯度并更新。w  w  Delta w  195  01  frac1195 approx 18987 。第四步计算第三轮梯度并更新。w  w  Delta w  18987  01  frac118987 approx 1846 。', '14已知卷积层中输入尺寸32  32 3有10个大小为55的卷积核stride1pad2输出大小为多少。输出特征图大小OH  OW  32  2  2  5  1   1  32。10个卷积核输出10个通道总特征数量10  32  32  10240', '15在把神经网络用于N个类别的分类任务时输出层一般采用N路softmax神经元和Cross Entropy误差函数但是在只有两个类别时一般直接用一个sigmoid神经元请证明2路softmax神经元和1个sigmoid神经元是等价的。答对于两路softmax神经元可以将其看作是两个sigmoid神经元的组合假设两路softmax神经元的输出为 y_1 和 y_2则有。y_1  fracez_1ez_1ez_2 。y_2  fracez_2ez_1ez_2。其中z_1 和 z_2 分别表示输入层到两个softmax神经元的连接权重与输入的线性组合。我们可以将两个式子相减得到。y_1  y_2  fracez_1ez_1ez_2  fracez_2ez_1ez_2  fracez_1ez_2ez_1ez_2。由于二分类任务中只有两个类别因此 y_2  1  y_1代入上式得到。y_1  1  y_1  2y_1  1  fracez_1ez_2ez_1ez_2。两边同时乘以 frac12得到。y_1  fracez_1ez_1ez_2  frac11ez_1z_2。可以发现这个式子和sigmoid神经元的输出函数形式是一样的只是输入变成了 z_1  z_2因此二分类问题中两路softmax神经元和一个sigmoid神经元是等价的', '16Faster RCNN中ROI pooling具体如何工作怎么把不同大小的框pooling到同样大小。答ROI pooling的主要作用是将候选区域的特征图处理成同样大小输出例如输入8x8的特征图输出2x2的特征图其工作原理入下。输入。ROI_pooling_inputimgROI_pooling_inputpng。第一步根据ROI projection算法计算候选区对应的特征图区域。ROI_pooling_projectionimgROI_pooling_projectionpng。第二步将其划分为2x2个区域针对每个区域做max pooling。ROI_pooling_projectionimgROI_pooling_maxpng。第三步产生输出。ROI_pooling_outimgROI_pooling_outpng', '17tensorflowwhile_loop和pythonfor循环的区别什么情况下for更优。答tensorflowwhile_loop和pythonfor循环的区别在于它们的执行方式。在tensorflow中while_loop是一个动态图操作它允许使用Python编写灵活的循环控制流并且能够在同一张计算图上多次重用相同的结构因此在需要在大量数据上进行迭代更新的情况下使用while_loop可以显著提高计算效率。而在Python中for循环是一个静态的迭代器需要将所有的元素都加载到内存中然后逐个遍历处理因此在处理小规模数据集或者只需要处理一次的任务时使用for循环通常更为简单和高效。总之选择使用while_loop还是for循环取决于具体的场景和任务需求如果需要在大量数据上进行迭代计算以及希望能够在同一张计算图上多次重复使用相同的结构则应该选择while_loop而如果只需要对少量数据进行处理或者只需要迭代一次则可以使用Python的for循环', '18Sigmoid函数的求导过程。答根据分数求导公式。frac UV  frac UV  UV V2。Sigmoid函数表达式y  frac11ex 先对分母部分求导。1  ex  ex lne  ex。再根据分数求导公式有。frac11ex  frac0  1ex  1  ex1ex2 。 frac1  ex 11ex2 。 frac1  ex1ex2  frac11ex2 。 frac11ex 1 frac11ex 。 fx1  fx。推导完毕', '19Sigmoid函数为什么会出现梯度消失Sigmoid函数导数最大值出现在哪个值Relu为什么能解决梯度消失问题。答Sigmoid函数当自变量大于某个值或小于某个值时函数梯度接近于0出现梯度消失当自变量的值为0时函数导数最大Relu大于0的部分梯度均为1所以避免了梯度消失情况', '20SSD和YOLO的区别YOLOv2和YOLOv3的区别。答1抛开具体实现上的差异 SSD检测精度优于YOLO3YOLO3检测时间快于SSD。2YOLOv2与YOLOv3的区别。 骨干网YOLOv3采用更深的Darknet53YOLOv2采用Darknet19。 分类器YOLOv3采用逻辑分离器YOLOv2采用softmax。 锚点YOLOv3采用9个锚点YOLOv2采用5个锚点。 多尺度融合YOLOv3采用13x13 26x26 52x52三种特征图进行特征融合YOLOv2采用13x13 26x26进行特征融合', '21测试集中有1000个样本600个是A类400个B类模型预测结果700个判断为A类其中正确有500个300个判断为B类其中正确有200个请计算B类的查准率Precision和召回率Recall。答可以建立以下混淆矩阵。       A     B    。      。 A     500   100  。 B     200   200  。类别B查准率200  200  100  23。类别B召回率200  200  200  12  05', '22训练模型时如果样本类别不均衡有什么办法解决如何判断模型是否过拟合对于神经网络中有哪些方法解决过拟合问题。答1对于类别不均衡问题可以对样本多的类别采用降采样对少的类别采用过采样。2通过对比训练集和测试集准确率判断模型是否过拟合如果训练集准确率较高测试集准确率较低则判断为过拟合。3见前面章节', '23神经网络节点激活函数的作用是什么SigmoidRelu和softmax函数的表达式是什么各自作用的优缺点是什么。答案见前面章节', '24下采样和上采样的理解。答对矩阵缩小称为下采样对矩阵放大称为上采样', '25深度可分离卷积是什么。答深度可分离卷积由depthwise卷积和pointwise卷积两部分结合起来在提取特征同时对数据进行降维。普通卷积输入5x5三通道图像4个3x3三通道卷积核总参数量为4  3  3  3  108如下图所示。common_convimgcommon_convpng。采用深度可分离卷积时先做逐通道卷积。common_conv_1imgcommon_conv_1png。再做逐点卷积。pointwise_convimgpointwise_convpng。最终得到四个通道的特征图但参数总量减少为。逐通道卷积3  3  3  27。逐点卷积1  1  3  4  12。共39个参数', '26目标检测常用算法有哪些简述对算法的理解。答目标检测可分为两阶段检测和一阶段检测两阶段检测先产生候选区再做分类和回归分类问题确定目标物体的类别回归问题确定目标物体的位置一阶段检测没有产生候选区的过程。1两阶段检测技术。 步骤先产生候选区再做分类和回归。 特点检测速度慢检测精度高。 代表性模型RCNNFast RCNNFaster RCNN系列SPPNet。2一阶段检测技术。 步骤直接在特征图上做分类和回归。 特点检测速度快检测精度较低。 代表性模型YOLO12345系列SSDRetinaNet', '27LSTM跟GRU的区别。答GRU是LSTM的简化版GRU参数更少因此更容易收敛但是数据集很大的情况下LSTM表达性能更好从结构上来说GRU只有两个门update和resetLSTM有三个门forgetinputoutput', '28用伪代码形式写出双线性插值的核心公式。答双线性插值又称为双线性内插在数学上双线性插值是有两个变量的插值函数的线性插值扩展其核心思想是在两个方向分别进行一次线性插值其原理为。blinear_insertimgblinear_insertpng。假如我们想得到未知函数f在点P xy 的值假设我们已知函数f在Q11  x1y1Q12  x1y2Q21  x2y1 以及Q22  x2y2 四个点的值首先在x方向进行线性插值得到R1和R2然后在y方向进行线性插值得到P。 第一步X方向的线性插值在Q12Q22中插入蓝色点R2Q11Q21中插入蓝色点R1。 第二步 Y方向的线性插值 通过第一步计算出的R1与R2在y方向上插值计算出P点。表示成公式。fR_1 approx fracx_2  xx_2  x_1 fQ_11  fracx  x_1x_2  x_1 fQ21   where R_1 x y_1 。fR_2 approx fracx_2  xx_2  x_1 fQ_12  fracx  x_1x_2  x_1 fQ22   where R_1 x y_2。29介绍一种图像特征提取方法如Sift特征Hog特征LBP特征等从方法实现的过程原理方法的用途特征的特点或其它你了解的方面任选一种介绍即可。1Sift特征。 SIFT全称是Scale Invariant Feature Transform尺度不变特征变换对旋转尺度缩放亮度变化等保持不变性是一种非常稳定的局部特征。 算法特点。 图像的局部特征对旋转尺度缩放亮度变化保持不变对视角变化仿射变换噪声也保持一定程度的稳定性。 独特性好信息量丰富适用于海量特征库进行快速准确的匹配。 多量性即使是很少几个物体也可以产生大量的SIFT特征。 高速性经优化的SIFT匹配算法甚至可以达到实时性。 扩展性可以很方便的与其他的特征向量进行联合。 步骤。 尺度空间的极值检测搜索所有尺度空间上的图像通过高斯微分函数来识别潜在的对尺度和选择不变的兴趣点。 特征点定位在每个候选的位置上通过一个拟合精细模型来确定位置尺度关键点的选取依据他们的稳定程度。 特征方向赋值基于图像局部的梯度方向分配给每个关键点位置一个或多个方向后续的所有操作都是对于关键点的方向尺度和位置进行变换从而提供这些特征的不变性。 特征点描述在每个特征点周围的邻域内在选定的尺度上测量图像的局部梯度这些梯度被变换成一种表示这种表示允许比较大的局部形状的变形和光照变换。 将图像image内的所有block的HOG特征descriptor串联起来就可以得到该image你要检测的目标的HOG特征descriptor了这个就是最终的可供分类使用的特征向量了。2Hog特征。 方向梯度直方图Histogram of Oriented Gradient HOG特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子它通过计算和统计图像局部区域的梯度方向直方图来构成特征。 算法过程。 灰度化。 采用Gamma校正法对输入图像进行颜色空间的标准化归一化目的是调节图像的对比度降低图像局部的阴影和光照变化所造成的影响同时可以抑制噪音的干扰。 计算图像每个像素的梯度包括大小和方向主要是为了捕获轮廓信息同时进一步弱化光照的干扰。 将图像划分成小cells统计每个cell的梯度直方图不同梯度的个数。 将每几个cell组成一个block例如33个cellblock一个block内所有cell的特征descriptor串联起来便得到该block的HOG特征。3LBP特征。 LBP是Local Binary Pattern局部二值模式的缩写具有灰度不变性和旋转不变性等显著优点。 原始的LBP算子定义为在3  3的窗口内以窗口中心像素为阈值将相邻的8个像素的灰度值与其进行比较若周围像素值大于等于中心像素值则该像素点的位置被标记为1否则为0这样3  3 邻域内的8个点经比较可产生8位二进制数通常转换为十进制数即LBP码共256种即得到该窗口中心像素点的LBP值并用这个值来反映该区域的纹理信息需要注意的是LBP值是按照顺时针方向组成的二进制数', '30求矩阵特征值特征向量或谈谈特征值分解或奇异值分解在图像中的应用。A  left。beginmatrix。1  2  3。4  5  6 。7  8  9。endmatrix。right。tag2。答。特征值分解在图像中的应用有。 图像压缩奇异值分解可以将一个大型图像矩阵分解为三个小型矩阵的乘积其中一个小矩阵包含了该图像的主要特征信息另外两个小矩阵则用于描述该图像在行和列方向上的变化通过选择只保留最重要的主成分即主要的奇异值可以实现对图像的压缩从而减少存储空间和传输带宽。 图像去噪特征值分解可以用于图像的去噪将一个含有噪声的图像矩阵进行特征值分解然后去掉一些较小的特征值再将矩阵合并起来可以得到一个近似于原始图像的新矩阵从而实现对图像的去噪。 图像增强特征值分解还可以用于图像的增强将一个需要增强的图像矩阵进行特征值分解然后调整一些较小的特征值的大小再将矩阵合并起来可以得到一个增强后的图像。 特征提取特征值分解和奇异值分解也可以用于图像的特征提取将一个图像矩阵进行特征值分解或奇异值分解然后提取其中的一些主要的特征向量就可以得到一个较低维度的特征空间从而实现对图像的有效描述和分类', '31写出一维傅里叶正逆变换公式或谈谈傅里叶变换在图像分析中有哪些作用。答一维傅里叶变换。Fu  sum_M0M1 fxejux frac2 piM u  012M1 。Rightarrow Fu  sum_M0M1 fxcosux frac2 piM  jsinux frac2 piM u  012M1。一维傅里叶逆变换。Fu  frac1Msum_u0M1 Fuejux frac2 piM x  012M1 。Rightarrow Fu  frac1M sum_u0M1 Fucosux frac2 piM  jsinux frac2 piM x  012M1。傅里叶变换用于在时域信号和频域信号之间进行转换在图像处理中能分离出图像高频部分和低频部分', '32常用图像分割算法有哪些各有什么优缺点。答1传统图像算法分水岭算法。2深度学习算法。 FCN模型又称全卷积网络去掉了CNN中的全连接层对输入图像进行层层卷积上采样预测出每个像素所属的类别。 UNet该模型对输入图像进行层层卷积上采样预测出每个像素所属的类别该模型简单高效容易理解容易定制针对样本较少的情况也能有较好分割效果。 Mask RCNN将Faster RCNN 上增加了FCN来产生定位和分割信息。 DeepLab系列引入了空洞卷积条件随机场多尺度空洞卷积等策略使得分割效果更好', '33简单介绍几种典型的传统人脸检测算法和基于深度学习的人脸检测算法。答1基于传统人脸检测算法Haar级联人脸检测算法。2深度学习人脸检测算法MTCNN模型Cascade CNN模型', '34简单介绍几种具有代表性的人脸识别模型结构及算法以及常用的损失函数。答1基于传统人脸识别算法LBPH人脸识别算法EigenFaces人脸识别算法。2深度学习人脸检测算法DeepFace模型FaceNet模型DeepID系列模型', '35简单介绍常用人脸活体检测算法可以从动作配合式和静默检测两个方面进行阐述。答所谓活体检测是指判断捕捉到的人脸是真实人脸还是伪造的人脸攻击如彩色纸张打印人脸图电子设备屏幕中的人脸数字图像 以及 面具 等', '36简单介绍几种常用的人脸属性及识别算法。答性别识别年龄估计种族识别表情识别', '37简单介绍几种典型传统文字行检测算法和基于深度学习的文字行检测算法。答文字检测是文字识别过程中的一个非常重要的环节文字检测的主要目标是将图片中的文字区域位置检测出来以便于进行后面的文字识别只有找到了文本所在区域才能对其内容进行识别。文字检测的场景主要分为两种一种是简单场景另一种是复杂场景其中简单场景的文字检测较为简单例如像书本扫描屏幕截图或者清晰度高规整的照片等而复杂场景主要是指自然场景情况比较复杂例如像街边的广告牌产品包装盒设备上的说明商标等等存在着背景复杂光线忽明忽暗角度倾斜扭曲变形清晰度不足等各种情况文字检测的难度更大。传统检测方法 包括形态学操作MSERNMS等方法深度学习文字检测主要包括CTPNSegLinkEAST等方法', '38简单介绍CRNNCTC和CRNNAttention文字行识别方法。答1CRNNCTC模型该模型主要实现了端对端的文字识别其主要流程为输入  卷积提取特征  特征图转序列  双向循环神经网络  CTC。2CRNNAttension模型该模型在CRNN网络的输出层后面加上一层Attention注意力机制Attention 机制在序列学习任务上具有巨大的提升作用在编解码器框架内通过在编码段加入Attention模型对源数据序列进行数据加权变换或者在解码端引入Attention 模型对目标数据进行加权变化可以有效提高序列对序列的自然方式下的系统表现', '39简述AdaBoostBP神经网络基本原理。答1Boosting也称为增强学习或提升法是一种重要的集成学习技术能够将预测精度仅比随机猜度略高的弱学习器增强为预测精度高的强学习器这在直接构造强学习器非常困难的情况下为学习算法的设计提供了一种有效的新思路和新方法作为一种元算法框架Boosting几乎可以应用于所有目前流行的机器学习算法以进一步加强原算法的预测精度应用十分广泛产生了极大的影响AdaBoost正是其中最成功的代表被评为数据挖掘十大算法之一其主要思想为。 先通过对N个训练样本的学习得到第一个弱分类器。 将分错的样本和其他的新数据一起构成一个新的N个的训练样本通过对这个样本的学习得到第二个弱分类器 。 将1和2都分错了的样本加上其他的新样本构成另一个新的N个的训练样本通过对这个样本的学习得到第三个弱分类器。 最终经过提升的强分类器即某个数据被分为哪一类要由各分类器权值决定。Aadboost 算法系统具有较高的检测速率且不易出现过适应现象但是该算法在实现过程中为取得更高的检测精度则需要较大的训练样本集在每次迭代过程中训练一个弱分类器则对应该样本集中的每一个样本每个样本具有很多特征因此从庞大的特征中训练得到最优弱分类器的计算量增大。2BP神经网络BPback propagation神经网络按照误差反向传播算法训练的多层前馈神经网络是应用最广泛的神经网络在神经网络训练过程中使用梯度下降法对模型参数进行优化因为深度神经网络存在隐藏层隐藏层的误差或偏导数不容易求解所以采用反向传播算法根据输出层的误差或参数偏导数一次倒退每个隐藏层的每个参数的误差或偏导数的方式进行训练', '40贝叶斯公式N个公司都考到了。答贝叶斯定义是通过先验概率计算后验的公式公式定义为。PAB  fracPAPBAPB。推导过程PA和PB是A事件和B事件发生的概率 PAB称为条件概率表示B事件发生条件下A事件发生的概率PAB为联合概率即时间A和B同时发生的概率则有。PAB PBPAB。PBA PAPBA。因为PABPBA 所以有。PBPABPAPBA。两边同时除以PB则得到贝叶斯定理的表达式', '41使用过哪些图像算法库。答opencvPIL', '42在你以前有关图像信号的处理工作中请列举你单独负责的项目并简述你在项目中的职责项目困难点在哪里是如何解决的。答参照关于项目问题的总结', '43简述常用边沿检测算子各有什么特性。答1Sobel算子Sobel算子是典型的基于一阶导数的边缘检测算子由于该算子中引入了类似局部平均的运算因此对噪声具有平滑作用能很好的消除噪声的影响Sobel算子对于象素的位置的影响做了加权与Prewitt算子Roberts算子相比因此效果更好Sobel算子包含两组3x3的矩阵分别为横向及纵向模板将之与图像作平面卷积即可分别得出横向及纵向的亮度差分近似值实际使用中常用如下两个模板来检测图像边缘。G_x  left。beginmatrix。1   0    1 。2   0    2 。1   0    1 。endmatrix。right       G_y  left。beginmatrix。1   2    1 。0   0    0 。1   2    1 。endmatrix。right。其中第一个为水平边沿检测模板第二个为垂直边沿检测模板图像的每一个像素的横向及纵向梯度近似值可用以下的公式结合来计算梯度的大小。G  sqrtG_x2  G_y2。2Prewitt算子Prewitt算子是一种一阶微分算子的边缘检测利用像素点上下左右邻点的灰度差在边缘处达到极值检测边缘去掉部分伪边缘对噪声具有平滑作用 其原理是在图像空间利用两个方向模板与图像进行邻域卷积来完成的这两个方向模板一个检测水平边缘一个检测垂直边缘对数字图像fxyPrewitt算子的定义如下。Gifi1j1fi1jfi1j1fi1j1fi1jfi1j1。Gjfi1j1fij1fi1j1fi1j1fij1fi1j1。则 PijmaxGiGj或 PijGiGj。Prewitt梯度算子法就是先求平均再求差分来求梯度水平和垂直梯度模板分别为。G_x  left。beginmatrix。1   0    1 。1   0    1 。1   0    1 。endmatrix。right       G_y  left。beginmatrix。1   1    1 。0   0    0 。1   1    1 。endmatrix。right。该算子与Sobel算子类似只是权值有所变化。3Laplace算子 Laplace算子是一种各向同性算子二阶微分算子在只关心边缘的位置而不考虑其周围的象素灰度差值时比较合适Laplace算子对孤立象素的响应要比对边缘或线的响应要更强烈因此只适用于无噪声图象存在噪声情况下使用Laplacian算子检测边缘之前需要先进行低通滤波所以通常的分割算法都是把Laplacian算子和平滑算子结合起来生成一个新的模板了更适合于数字图像处理将拉式算子表示为离散形式。bigtriangledown 2f  fracpartial 2 fpartial x2  fracpartial 2 fpartial  y2。离散拉普拉斯算子的模板。G_x  left。beginmatrix。0   1    0 。1   4    1 。0   1    0 。endmatrix。right       G_y  left。beginmatrix。1   1    1 。1   8    1 。1   1    1 。endmatrix。right。4Canny算子该算子功能比前面几种都要好但是它实现起来较为麻烦Canny算子是一个具有滤波增强检测的多阶段的优化算子在进行处理前Canny算子先利用高斯平滑滤波器来平滑图像以除去噪声Canny分割算法采用一阶偏导的有限差分来计算梯度幅值和方向在处理过程中Canny算子还将经过一个非极大值抑制的过程最后Canny算子还采用两个阈值来连接边缘其步骤为。step1 用高斯滤波器平滑图象。step2 用一阶偏导的有限差分来计算梯度的幅值和方向。step3 对梯度幅值进行非极大值抑制。step4 用双阈值算法检测和连接边缘', '44简述常用图像去噪方法各有什么特性N个公司都考到了。答1均值滤波在N领域内求均值。2中值滤波在N邻域内求终止对椒盐噪声抑制效果较好图像细节损失较大。3高斯滤波采用满足高斯分布的滤波器进行滤波大小标准差可根据参数设置。4双边滤波在保留轮廓清晰的情况下进行降噪处理', '45请列举几种常用的图像空间。答图像空间指图像的色彩表示方式常用的有RBGHSVYUV等色彩空间', '47常用插值算法有哪些。答最邻近插值法双线性插值法', '48什么叫算子请列举常用的边沿检测算子。答算子Operator是一个数学概念它将一个元素在向量空间或模中转换为另一个元素的映射简单来说就是独立的计算单元或规则常用边沿检测算子有Sobel算子Prewitt算子Laplacian算子Canny算子', '51判断题以下说法是否正确。 拉普拉斯算子可用于图像平滑处理错误。 高频加强滤波器可以有效增强图像边沿和灰度平滑区的对比度正确。 彩色图像增强时采用RGB模型进行直方图均衡化可以在不改变图像颜色的基础上对图像的亮度进行对比度增强错误', '52将高频加强和直方图均衡相结合是得到边沿锐化和对比度增强的有效方法上述两个操作先后顺序对结果有影响吗为什么nan', '54HOUGH变换的原理是什么HOUGH变换用在检测圆上应该怎么做。答HOUGH霍夫变换主要用于检测图像中的简单几何形状如直线线段圆形椭圆等在使用HOUGH变换检测圆形时实际是找边沿是否满足x y为中心R为半径的圆的方程式在实际使用中可以先对图像进行灰度化处理二值化处理或求图像轮廓梯度信息再使用HOUGH变换以获得更好的效果', '55简述傅里叶变换在图像处理中的应用。答傅里叶变换是将时域信号转换为频域信号的一种方式简单来说该变换能将一组周期信号转变为多个正弦信号的叠加在图像处理中利用傅里叶变换可以分离出图像的高频部分低频部分从而提取出图像的轮廓边沿或轮廓边沿以外的部分', '56什么是神经网络有什么主要特点选择神经网络应该考虑什么因素。答见讲义部分', '57解释线性判别。答LDA是一种监督学习的降维技术也就是说它的数据集的每个样本是有类别输出的其思想可以用一句话概括就是投影后类内方差最小类间方差最大即将数据在低维度上进行投影投影后希望每一种类别数据的投影点尽可能的接近而不同类别的数据的类别中心之间的距离尽可能的大如下图所示。LDA_1imgLDA_1png。例如有以下两种投影方式第二种投影方式更好因为红色数据和蓝色数据各个较为集中且类别之间的距离明显。LDA_1imgLDA_2png。在实际应用中数据是多个类别的我们的原始数据一般也是超过二维的投影后的也一般不是直线而是一个低维的超平面', '58深度学习中常见的layer的类别有哪些其作用分别是什么。答常见的层有。 卷积层卷积运算提取特征。 池化层降维提升模型泛化能力。 激活层执行激活运算。 全连接层充当分类器。 BNBatch Normal层缓解梯度消失缓解过拟合加快模型收敛速度和稳定性。 Dropout丢弃学习层缓解梯度消失在有些模型中使用BN则不使用dropout', '59常用的图像二值化方法及使用示例。答1阈值分割法设定一个阈值用每个图像的像素值跟阈值进行比较大于阈值设为最大值小于阈值设为最小值实现图像二值化。2自适应阈值分割法程序自动寻找分割阈值分割结果前景背景类间方差最大。60写出Sobel算子拉普拉斯算子以及它们梯度方向上的区别并编程实现。答见前面', '61列出机器学习中常见的分类算法并比较各自的特点。答机器学习中常见的分类算法有。1线性分类器使用线性模型计算连续值然后进行离散化处理特点是计算相对简单。2支持向量机二分类模型寻找最优线性分类边界所谓最优分类边界指支持向量间隔最大化强分类器。3决策树决策树根据样本属性构建一个树状结构将具有相同属性的样本划分到一个子节点下通过投票法产生分类结果弱分类器。4朴素贝叶斯利用贝叶斯定理计算样本属于某个类别的概率分类到概率最高的类别中所谓朴素指假设特征之间是独立的。5KNN找与这个待分类样本在特征空间中距离最近的K个已标注样本作为参考做出分类决策', '62二值图灰度图及RGB彩色图像的概念表示及存储。答1二值图图像灰度值只有两种颜色。2灰度图只有亮度信号没有色彩信号灰度图像表示一个单通道矩阵。3彩色图像包含彩色信号的图像彩色图像表示一个三通道数组RGB色彩空间三个通道分别存储红色绿色蓝色三原色信息HSV色彩空间分别存储图像的色相饱和度和亮度', '63实现对一彩色图像的灰度化算法可以写多个。答1平均值法。2最大值法。3取单通道值。4加权平均法', '64数码相机大多使用jpg格式存储数字相片如果一般情况下jpg格式的压缩比为510请估计使用500万像素数码相机所拍摄到的彩色数字相片的高宽以及文件大小nan', '65你是否学习或接触过数字图像技术如果学习或接触过试写一算法实现将彩色图像旋转180度nan', '66给定一个nn的二维矩阵表示一个图像将图像顺时针旋转90度并在下方写出代码说明必须在原地旋转这意味着需要直接修改输入二维矩阵不要使用另一个矩阵来旋转图像。原矩阵。1 2 3。4 5 6。7 8 9。旋转后。7 4 1。8 5 2。9 6 3。', '67朴素贝叶斯分析的关键假设是什么基于几点需要做这样的假设。答假设样本特征是独立的不相互影响在计算中如果不引入该假设可能某些先验概率无法计算出来', '68简述kmeans算法的输入输出及聚类过程。答见前面章节', '69基于用户协同过滤的算法思想是什么。答基于用户协同过滤的算法是一种推荐系统算法它基于用户之间的相似性来提供个性化推荐。该算法的基本思想是根据用户历史行为数据例如购买评分点赞等计算不同用户之间的相似度然后将这些相似用户的兴趣偏好进行合并形成推荐列表并向用户推荐。具体而言该算法分为两个阶段。 计算用户之间的相似度首先需要选择一个相似度度量方法如余弦相似度欧几里得距离皮尔逊相关系数等然后根据用户历史行为数据计算不同用户之间的相似度得分。 基于相似用户的历史行为生成推荐列表对于目标用户选取与其相似度较高的一些用户然后将这些用户在某一领域内的历史行为进行汇总生成推荐列表并向目标用户进行推荐。基于用户协同过滤的算法可以处理大规模数据和复杂数据类型容易实现和解释并且能够提供高质量的个性化推荐缺点是需要依赖用户历史行为数据如果用户数据量较少或者用户行为存在一定的随机性可能会导致推荐结果不准确', '70我们想要减少数据集中的特征即降维选择以下合适的方案ABCD。A使用前向特征选择方法。B使用后向特征选择方法。C先把所有特征都使用去训练一个模型得到测试集上的表现然后去掉一个特征再去训练用交叉验证看看测试集上的表现如果表现比原来好可以去除这个特性。D查看相关性表去除相关性高的一些特征。解析特征选择  Feature Selection 也称特征子集选择 Feature Subset Selection  FSS  或属性选择 Attribute Selection  是指从全部特征中选取一个特征子集使构造出来的模型更好特征越多维度越高模型分析训练越复杂且容易引起过拟合选择特征方法有。 序列前向选择 SFS  Sequential Forward Selection 特征子集X从空集开始每次选择一个特征x加入特征子集X使得特征函数J X最优简单说就是每次都选择一个使得评价函数的取值达到最优的特征加入其实就是一种简单的贪心算法。 序列后向选择 SBS  Sequential Backward Selection 从特征全集O开始每次从特征集O中剔除一个特征x使得剔除特征x后评价函数值达到最优。 双向搜索 BDS  Bidirectional Search 使用序列前向选择SFS从空集开始同时使用序列后向选择SBS从全集开始搜索当两者搜索到一个相同的特征子集C时停止搜索。 增L去R选择算法  LRS  PlusL MinusR Selection 算法从空集开始每轮先加入L个特征然后从中去除R个特征使得评价函数值最优 L  R  算法从全集开始每轮先去除R个特征然后加入L个特征使得评价函数值最优 L  R 。 决策树利用决策树进行特征筛选', '71ResNet网络最后两层是什么。答ResNet最后三层为平均池化层全连接层softmax产生1000路输出', '84简述CNNLSTM原理和两者适合应用的场合叙述CNN如何进行特征提取分类预测。答原理见讲义。适用场景CNN主要用于图像问题LSTM主要用于序列问题如NLP语音识别', '85图像处理中高通滤波低通滤波的作用是什么。答低通滤波起平滑作用高通滤波起锐化作用', '92简述densnet结构及特点。答DenseNet是一种密集连接卷积神经网络它的主要结构特点是在网络中的每一层都将前面所有层的输出作为输入DenseNet通过这种方式促进了信息和梯度的流动增加了网络的稠密性也降低了模型参数量此外DenseNet还采用了批次归一化和ReLU非线性激活函数等常见的技术以提高模型的性能和训练速度相对于其他卷积神经网络DenseNet在对小数据集进行训练时表现更好并且具有更好的特征重用能力', '93YOLO5做了哪些改进YOLO3和YOLO5主要区别有哪些。答相比YOLOv3YOLOv5在以下几方面进行了改进。 轻量化YOLOv5网络结构更加轻量级可在保持较高精度的情况下实现更快的推理速度。 SPP模块引入了空间金字塔池化SPP模块在不同尺度上提取特征从而增强感受野。 PANet结构引入了特征金字塔网络PANet结构可以更好地处理不同大小的目标。 数据增强策略使用更多的数据增强策略例如自适应缩放随机翻转色彩变换等以提高模型的鲁棒性和泛化能力。 模型训练采用更高效的模型训练方法例如基于MixUp的数据增强和类别平衡损失函数等。相对于YOLOv3YOLOv5主要的区别在于网络结构和性能表现YOLOv5具有更轻量级的网络结构和更快的推理速度同时也取得了更好的物体检测精度', '94cpu和gpu有什么区别。答CPU中央处理器和GPU图形处理器都是计算机的核心部件它们的主要区别在于其设计目标和工作方式。CPU是一种通用处理器其设计目标是针对各种不同类型的任务进行优化例如操作系统办公软件或浏览器等CPU通常包含少量的核心通常是216个并且每个核心可以执行多个任务CPU的设计目标是实现快速响应和高度灵活性而不是处理大量数据的复杂计算问题。GPU则是一种专门用于图形处理和并行计算的处理器其设计目标是加速图形和计算密集型任务例如视频游戏科学计算和深度学习等GPU通常包含数百个甚至数千个小型处理单元可以同时处理大量数据并执行并行计算这使得GPU在处理大规模数据和密集计算时比CPU更有效率。总体来说CPU适用于广泛的通用计算任务而GPU则适用于需要高性能数值计算和图像处理的任务', '95yolov5后处理的代码怎么写。答YOLOv5的后处理代码包括两个主要步骤解码预测和筛选边界框。 解码预测在YOLOv5中每个预测都包含一个类别得分张量和一个边界框偏移张量为了将这些预测转换为实际边界框我们需要对它们进行解码以下是解码预测的Python代码示例。python。def decode_predictionspredictions anchors num_classes input_shape。 获取特征图大小。grid_size  predictionsshape13。 获取锚框数量。num_anchors  lenanchors。 将预测结果重塑为二维数组。predictions  npreshapepredictions 1 num_anchors  5  num_classes。 转换锚框形状。anchors  nptileanchors grid_size0  grid_size1 1。 计算边界框坐标。box_xy  sigmoidpredictions 2。box_wh  npexppredictions 24  anchors。box_confidence  sigmoidpredictions 4。box_class_probs  softmaxpredictions 5。 调整边界框坐标到原始输入尺寸。xy_offset  nparangegrid_size1  05  grid_size1。xy_offset  npstackxy_offset  grid_size0。xy_offset  npexpand_dimsnpstackxy_offset  num_anchors axis1 axis2。box_xy  xy_offset。box_xy  grid_size1。box_wh  input_shape1。 计算边界框左上角和右下角坐标。box_mins  box_xy  box_wh  2。box_maxes  box_xy  box_wh  2。boxes  npconcatenatebox_mins box_maxes axis1。return boxes box_confidence box_class_probs。 筛选边界框解码预测后我们需要对边界框进行筛选以滤除低置信度的边界框并将重叠的边界框合并成单个边界框以下是筛选边界框的Python代码示例。python。def filter_boxesboxes scores classes score_threshold iou_threshold。 在每个类别上应用置信度阈值。indices  npwherescores  score_threshold0。boxes  boxesindices。classes  classesindices。scores  scoresindices。 非最大抑制。selected_indices  non_max_suppressionboxes classes scores iou_threshold。return boxesselected_indices scoresselected_indices classesselected_indices。', '96mmdetection模型是什么用法配置能处理的方向是什么。答mmdetection是一个基于PyTorch的目标检测开源框架提供了丰富的预训练模型和检测器实现它支持各种目标检测任务如物体检测实例分割人脸检测等并提供了多种优秀的检测算法包括Faster RCNN Mask RCNN RetinaNet FCOS等。用法 mmdetection提供了简单易用的命令行工具可以轻松地训练测试和评估模型可以通过以下步骤使用mmdetection。 安装mmdetection可通过pip安装或者从GitHub克隆源代码并安装相关依赖。 准备数据集将数据集按照指定格式准备好包括图片和标注文件。 配置训练参数mmdetection提供了各种不同的配置文件可以选取适合自己的配置文件并根据需要进行修改。 开始训练运行训练命令即可开始训练模型。 测试和评估训练完成后可以使用测试命令对模型进行测试并使用评估命令评估模型性能。配置 mmdetection的配置文件采用Python语言编写并采用了易于理解的字典结构配置文件的主要内容包括数据集路径模型结构训练参数等可以根据需要选择不同的配置文件并进行修改以满足自己的需求。能处理的方向 mmdetection支持各种目标检测任务包括物体检测实例分割人脸检测等它提供了多种优秀的检测算法可以根据自己的需求选择不同的算法进行检测同时mmdetection还支持多种数据增强策略和训练技巧可以帮助用户快速搭建高效且准确的检测模型', '97决策树算法怎么搭建的nan', '98网络一般是重新训练还是迁移权重nan', '99训练模型时候有什么问题训练模型有没有遇到什么怪问题nan', '100梯度下降局部最优怎么解决。梯度下降方法在优化神经网络等高维非凸函数时可能会陷入局部最优解为了避免陷入局部最优以下是一些解决方法。 随机初始化通过多次随机初始化权重和偏置可以增加找到全局最优解的机会。 梯度裁剪通过裁剪梯度的大小可以防止梯度出现异常值并使其保持在一个合理的范围内从而更快地收敛。 学习率调整学习率是控制模型参数更新步长的超参数它的大小对模型的性能和收敛速度有很大影响可以通过动态调整学习率的大小来平衡模型的收敛速度和稳定性。 正则化通过添加正则化项如L1或L2正则化来限制模型参数的大小从而防止过拟合并使得模型更容易跳出局部最优。 神经架构搜索通过搜索不同的神经网络结构可以找到更好的初始点从而更有效地避免陷入局部最优神经架构搜索需要大量计算资源和时间但可以获得显著的性能提升。 随机梯度下降传统的梯度下降在每次迭代中使用所有数据进行更新而随机梯度下降SGD则是每次迭代中只使用部分数据这样可以使模型更容易跳出局部最优并且加速训练过程。 梯度下降变种像MomentumAdagradRMSPropAdam等梯度下降的变种方法也可以有效地避免陷入局部最优这些方法通过考虑过去梯度信息或者改变梯度下降的方向和步长来达到这个目的', '101opencv 的底层原理是什么。答OpenCV是一种开源的计算机视觉库为计算机视觉和机器学习提供了大量的函数和工具其底层原理涵盖以下几个方面。 数据结构OpenCV中使用了包括Mat等多种数据结构用于表示图像矩阵等数据。 图像处理OpenCV支持基本的图像处理操作如裁剪缩放旋转滤波等这些操作通常通过卷积运算实现。 特征检测OpenCV提供了多种特征检测算法如SIFTSURFHarris角点检测等。 目标检测和跟踪OpenCV提供了多种目标检测和跟踪算法如Haar级联检测器人脸识别KCF跟踪器等。 机器学习OpenCV提供了多种机器学习算法如支持向量机SVM人工神经网络随机森林等。 硬件加速OpenCV可以利用CPUGPUFPGA等硬件进行加速提高计算速度。总体来说OpenCV的底层原理主要是基于数学计算的图像处理与分析技术通过对图像进行数字化处理提取图像的特征信息进而实现图像识别目标检测和跟踪等计算机视觉应用', '102AI芯片的基本结构与原理。答AI芯片AI chip是专门为人工智能AI应用而设计的芯片其基本结构和原理可以分为以下几个方面。 硬件架构AI芯片通常采用并行计算架构比如深度神经网络DNN中的卷积神经网络CNN使用的是卷积层池化层全连接层等计算单元此外还包括特定的加速器存储单元和输入输出接口等。 计算单元AI芯片中最重要的计算单元就是矩阵乘法单元该单元通常由一组多元并行运算单元和一组数据寄存器组成这些单元能够对大量的数据进行高效的并行计算从而提高了计算效率。 存储单元AI芯片中的存储单元主要包括内存和缓存在深度学习中由于数据量很大因此需要大容量的内存来存储数据和模型参数同时为了提高计算效率还需要快速的缓存可以预先存储部分数据以便计算单元快速访问。 算法优化AI芯片还需要针对不同的任务进行算法优化比如使用定点算法来代替浮点算法以取得更高的运算速度和计算精度。总之AI芯片的基本结构和原理主要是针对深度学习等人工智能应用进行设计的并与传统的通用计算机硬件有所不同它包括了矩阵乘法单元存储单元各种加速器输入输出接口等部分以便实现高效的数据处理和计算同时也需要进行算法优化以最大程度地提高计算效率和精度', '104给2个多边形他们有相切相交相邻使用什么方法可以给他们合并。答如果两个多边形相切相交或相邻可以使用布尔运算中的合并操作Union将它们合并成一个新的多边形具体来说可以使用裁剪算法Clipping Algorithm实现布尔运算常用的裁剪算法包括 SutherlandHodgman 算法WeilerAtherton 算法等', '105kmeans无监督学习和yolov3有监督学习是怎么搭配使用。答可以使用kmeans来对数据进行聚类然后将每个簇中心点作为yolov3的初始 anchor box这样可以有助于提高yolov3的检测精度具体步骤如下。 使用kmeans算法将训练集中的bounding box聚成K个簇。 对于每个簇计算它们的中心点作为yolov3的一个anchor box。 将这些anchor box加入yolov3的训练集中重新训练yolov3模型', '106mAP值是如何计算的。答mAPmean Average Precision指的是平均精度均值是用来评估目标检测算法性能的指标它的计算方法如下。 对于每个类别将检测结果按照置信度从大到小排序。 依次计算每个预测框的精度和召回率并绘制出精度召回率曲线。 计算该类别下面积最大的精度召回率曲线下的面积作为该类别的APAverage Precision。 对所有类别的AP求平均得到mAP。其中精度指的是检测出来的正样本中真实正样本的比例即 TP  TP  FP召回率指的是真实正样本中检测出来的正样本的比例即 TP  TP  FN', '107用opencv检测到单独每个点的坐标吗比如可以取到树叶每个点的坐标  或者边缘或者树叶的尖的点的坐标。答可以使用边缘检测算法如Canny边缘检测再结合轮廓发现函数 findContours 来提取出树叶和尖端的轮廓信息通过遍历轮廓上的每个点就可以得到每个点的坐标', '108焦点损失函数平衡因子和比例失调是什么。答焦点损失函数Focal Loss Function是一种在处理类别不平衡问题时常用的损失函数它可以让模型更加关注难以分类的样本平衡因子Balance Factor是指在计算损失时为了平衡不同类别的权重而引入的一个系数而比例失调Ratio Imbalance则是指正负样本之间的数量差异。具体来说焦点损失函数通过降低容易分类的样本的权重将更多的注意力放在难以分类的样本上从而提高模型对于难以分类样本的预测能力如果将焦点损失函数表示为 FLp_talpha_t1p_tgamma logp_t其中 p_t 表示模型预测的概率alpha_t 是平衡因子gamma 是调节焦点损失的超参数当 gamma0 时焦点损失函数等价于交叉熵损失函数。另外由于在某些任务中正负样本的数量可能会存在较大的差异这就导致了类别不平衡问题的出现此时除了使用焦点损失函数外还可以通过设置平衡因子来平衡不同类别的权重平衡因子通常定义为反类别频率的倒数即 alpha_tfrac1sum_t n_t其中 n_t 表示第 t 个类别的数量。最后比例失调是指正负样本之间的数量分布不均衡这可能会导致模型在训练过程中对于某些类别的预测能力出现偏差为了解决这个问题可以采用上述提到的方法来处理类别不平衡问题', '109项目上线都是怎么维护的上线后客户有问题怎么解决怎么跟进。答日常维护由运维人员来完成如果模型出现了漏检误检会反馈给算法组进行评估和优化如果检测物体有变化需要重新评估后调整数据集进行训练评估更新模型。110文字识别处理检测等有哪些来源的写好的库可以调用。答百度的PaddleOCRDocTR Tesseract ChineseOCR还有华为阿里等云计算平台提供的OCR服务可以用', '111图像膨胀腐蚀的原理是什么。答图像膨胀Dilation和腐蚀Erosion是形态学图像处理中常用的基本操作它们可以通过对二值化图像中的像素进行操作来改变图像中目标区域的形态和大小。膨胀操作的原理是将目标区域向外扩张使得其周围的背景区域被逐渐填充具体来说膨胀操作会遍历所有像素并将每个目标像素与其周围的若干个像素进行比较如果周围至少有一个像素是目标像素则当前像素也被视为目标像素这样就可以将目标像素向周围扩张从而增加目标区域的大小和粗细。腐蚀操作的原理则是将目标区域向内缩小使得其周围的背景区域被逐渐削弱具体来说腐蚀操作也会遍历所有像素并将每个目标像素与其周围的若干个像素进行比较如果周围所有的像素都是目标像素则当前像素也被视为目标像素这样就可以将目标像素向周围收缩从而减少目标区域的大小和粗细', '问整个项目规模大概多少人参与你负责哪个部分。答根据项目规模不同项目成员及分工有所不同。1大型项目一个项目组大约数十人或数百人项目周期12年例如华为云计算AI服务车辆自动驾驶系统项目成员及分工。 算法工程师数人负责算法开发调试评估优化。 算法部署工程师数人负责算法压缩裁剪部署。 软件开发工程师数十人负责前端后端开发。 测试工程师数人负责整个 系统测试。 数据标注外包给数据公司或雇佣低成本人员。2中型项目一个项目组1030人项目周期612个月例如直播平台行为监控智慧社区网站文本图片内容审核平台财务票据识别系统项目成员及分工。 算法工程师25人负责算法开发调试评估优化。 算法部署工程师13人负责算法压缩裁剪部署。 软件开发工程师1020人负责前端后端开发。 测试工程师25负责整个 系统测试。 数据标注外包给数据公司或雇佣低成本人员。3小型项目10人以下36个月例如质检系统。 算法工程师12人负责算法开发调试评估优化。 算法部署工程师1人或算法工程师承担部署工作负责算法压缩裁剪部署。 软件开发工程师35人负责前端后端开发。 测试工程师1人或项目组自测负责整个 系统测试', '问样本是怎么收集的。答。 图像类数据相机拍摄从视频中抽帧从影视剧中采集。 文字或文本数据爬虫从网络爬取自己收集。 企业业务数据从企业经营活动中收集。 特殊数据采集X光数据超声波数据激光 雷达数据气象数据卫星遥感数据等采用特殊设备采集', '问实际的摄像头是怎么采集的。答。 图像数据采用从摄像头中抽帧的方式。 视频数据从摄像头中读取视频段', '问如果某一个物品里摄像头远拍的照片小跟真样本大小还是有区别的这是怎么解决的主要是数据清洗这块如何解决。答训练阶段采集的样本应该跟真实运行环境样本一样如果有不一致的地方可以采用图像变换缩放等处理手段调整为一致', '问如果模型训练好后后续又增加了几个商品如何处理。答采集样本重新训练模型重新部署', '问最终部署是使用一个模型还是多个模型。答根据具体情况确定如果检测识别项目或类别较少一个 模型即可如果检测识别项目或类别较多可以训练部署为多个模型共同配合完成识别任务', '问整理样本的时候有没有稀疏性如果遇到这种问题怎么解决。答样本稀疏指训练样本少 此外可能伴随特征过多的情形维度灾难处理方法。 数据层面数据增强合成数据。 模型层面模型正则化交叉验证集成学习选择合适的模型。 方法层面迁移学习然后对模型微调', '问是否刚开始选用的模型精度不高做不同模型之间的对比。答这种情况较为常见刚选择的模型精度不够需要更换模型有些需求不知道哪个模型更好就使用多个模型进行效果对比择优使用', '问线上服务器怎么调用的。答线上服务器一般指网络服务器监听一个IP地址和端口为客户端提供数据服务客户端通过TCPIP协议进行调用在应用层一般使用HTTP协议调用接口采用Restful风格', '问对视频的提取频率是多少。答这个问题实际问的是从视频中抽帧的频率取决于检测或识别的速度如果视频中的物体在高速移动例如交通车辆检测每秒抽帧数量就需要较多如果视频中的物体在低速移动每秒抽帧数量就需要较少在有些系统或模型中会同时进行高频低频抽帧这样能捕获物体运动的高频低频或快速慢速特征', '问如果准确率在实际使用中有浮动怎么做优化。答这个问题问的很泛需要找到准确率波动的原因是什么然后采取相应的措施来处理', '问为什么对特征做标准化。答在机器学习中对特征做标准化也称为归一化是一个非常重要的预处理步骤原因如下。 加速收敛基于梯度下降的算法如线性回归逻辑回归神经网络等在训练过程中需要计算梯度如果特征的尺度差异很大梯度的大小和方向会受到较大影响导致训练过程收敛缓慢甚至无法收敛。 提高算法性能一些算法如支持向量机K近邻算法等对特征的尺度非常敏感如果特征的尺度不一致这些算法的性能可能会显著下降在KMeans算法中如果某个特征的尺度远大于其它特征那么距离计算将主要依赖于这个特征导致其它特征的信息被忽略。 避免数值问题在某些情况下特征的尺度差异过大可能导致数值计算问题如溢出或下溢标准化可以确保所有特征都在一个合理的数值范围内从而避免这些问题。 简化模型解释标准化后的特征具有相似的尺度这使得模型的权重或系数更加直观和可解释如果特征的尺度差异很大模型的权重可能会因为尺度的不同而显得难以理解。 提升正则化效果在使用正则化技术如L1正则化L2正则化时标准化可以确保所有特征都受到相同的惩罚力度如果特征的尺度不一致正则化可能会更多地惩罚那些尺度较大的特征导致模型偏向于选择那些尺度较小的特征这通常不是我们希望看到的结果', '问用什么方法进行标准化处理。答标准化通常涉及将特征值减去其均值并除以其标准差使得处理后的特征值具有零均值和单位方差', '问上采样的原理是什么。答上采样即数据放大方式主要有三种双线性插值最邻近插值转置卷积。 双线性插值在两个维度上都根据数据线性变化规律插值从而实现上采样。 最邻近插值插值时找离当前需要插值位置最近的点将该点的值作为当前插入的值。 转置卷积卷积运算在计算时为了加速转换为矩阵乘法转置卷积在做卷积时将其中一个矩阵做转置卷积输出矩阵比输入矩阵大', '问网络初始化所有参数为0可以训练吗。答不可以见前面章节', '问为什么最大池化更常用。答最大池化有以下优点。 保留更关键特征最大池化通过从每个局部区域中选择最大值来降低特征图的尺寸这种机制能够有效地保留图像中的显著特征即那些对于图像分类目标检测等任务至关重要的特征由于最大值往往代表了图像中的最强响应因此最大池化有助于模型捕捉到最重要的视觉特征。 平移旋转缩放不变性最大池化对输入数据的小变化如图像中的轻微位移旋转或缩放具有一定的鲁棒性这是因为最大池化主要关注局部区域内的最大值而不太受具体位置的影响这种特性使得模型对于图像中的微小变化更加稳健。 减少过拟合最大池化的降采样特性模型对于训练数据中的特定样本细节变得不那么敏感这有助于减少过拟合的风险提高模型的泛化能力', '问什么情况下会用到平均池化。答以下情况会用到平均池化。 需要保留整体数据特征时平均池化通过对输入数据的局部区域内所有值求平均来降低特征图的尺寸这种方法能够保留图像或特征图的整体数据特征尤其是当图像中的信息都应该有所贡献时例如在图像分割任务中全局平均池化常用于获取全局上下文关系有助于模型对整体结构的理解。 网络深层的高级语义信息提取在网络深层特征图通常包含较多的高级语义信息这些信息对于分类器来说通常都很有帮助因此在需要利用这些高级语义信息进行分类或其他任务时平均池化可能是一个更好的选择例如在图像分类任务中对最后的特征图进行平均池化而不是最大池化有助于模型更好地利用全局信息来提高分类准确率。 减少模型对局部变化的敏感度与最大池化相比平均池化对输入数据的局部变化更加敏感然而在某些情况下这种敏感性可能是有益的例如在需要模型对图像中的细微变化进行响应时尽管这种情况相对较少平均池化可能更合适但需要注意的是过度敏感可能导致模型对噪声或无关细节产生过拟合。 与其它池化方法的结合使用在某些情况下平均池化和最大池化可以结合使用以充分利用两者的优点例如可以先使用最大池化来提取图像中的显著特征然后再使用平均池化来平滑这些特征并保留整体结构信息这种结合使用的方法可能有助于提高模型的性能和鲁棒性', '问yolov5的损失函数怎么表达。答包括三部分定位损失函数分类损失函数置信度损失函数YOLO5输出三种大小张量32倍降采样16倍降采样 8倍降采样在每种大小输出张量上解析每个输出值分别跟标签值进行比较将三种大小损失值合并到一起作为整个模型的损失函数。yolo5lossimgyolo5losspng。其中L_box表示定位损失函数L_cls表示分类部分损失函数L_obj表示有没有物体的置信度预测损失函数下标ij表示输出张量第i行第j列个预测结果对应原图上的每个小格子1_ij obj并表示有物体情况下设置为11_ij noobj表示没有物体情况下设置为1', '问交叉熵可以用于回归问题吗均方误差可以用于分类问题吗。答交叉熵衡量的是两个概率分布之间的差异理论上可以在回归问题中使用交叉熵但这通常不是最佳选择回归问题的输出通常是连续值而不是概率分布因此交叉熵在这种情况下可能不是合适的损失函数。均方误差可以用于分类问题但会导致误差梯度过小的问题', '问说出三个点与点之间距离的度量方式。答欧氏距离曼哈顿距离棋盘距离', '问在BEVformer中如何通过可变性注意力机制将提取的特征转变成BEV特征的是否使用了时序融合的模块前后融合了多少帧算力不够如何改进nan', '问Transformer的原理和结构几种注意力机制。答见NLP讲义', '问在Transformer中计算相似度的原理也可以说在数学空间中如何计算两个向量的相似度。答利用点乘计算向量的相似度', '问YOLO中anchor based 和anchor free 有什么区别。答anchor based和anchor free是两种不同的目标检测方法。1Anchor Based。 定义也被称为基于锚框的检测方法它预先设置目标可能存在的大概位置即锚框然后再在这些预设框的基础上进行精细化的调整调整过程包括分类判断预设框是属于正样本还是负样本以及回归调整预测框的位置。 优点可以产生密集的锚框使得网络可以直接进行目标分类和边界框回归提高了目标的召回能力。 缺点需要设定很多超参数如尺度长宽比等这些超参数的设定会影响检测性能另外该方法也会产生很多冗余的框增加了计算量和内存消耗。2Anchor Free。 定义无锚框检测方法它不需要预设的锚框而是将目标检测转化为关键点检测或目标物体中心定位的问题。 优点不需要预设锚框减少了计算量同时也可以避免一些由于锚框设置不合理导致的漏检和重复检测的问题。 缺点由于每个位置只预测一个框可能会导致一些重叠或遮挡区域无法被检测另外需要设置一些特殊的损失函数或结构来提高精度和稳定性', '问DeepLabV3的损失函数是什么。答用每个像素预测的类别和这个像素真实类别构建像素级交叉熵', '问简单说一下分布式训练的原理和过程。答分布式训练的基本原理是将原本巨大的训练任务拆分成多个子任务每个子任务在独立的计算节点如CPUGPUTPU或NPU上单独执行这些计算节点通过网络进行通信共享模型参数和梯度信息从而实现模型的同步更新这种方式有效解决了单机训练中的计算瓶颈和内存限制问题显著加速了训练过程分布式训练主要分为两种类型数据并行和模型并行。1数据并行。 在数据并行中训练数据集被拆分成多个子集每个计算节点处理一个子集。 每个计算节点都存储有整个神经网络模型的完整副本。 在迭代过程中每个计算节点根据本地数据子集进行前向计算和反向传播得到梯度。 所有计算节点需要聚合其他节点计算的梯度值然后使用平均梯度对模型进行更新。2模型并行。 在模型并行中神经网络模型被拆分成多个部分每个计算节点负责模型的一个部分。 模型并行通常用于解决单节点内存不足的问题或者当模型规模过大无法在一个节点上完整存储时。 模型并行可以分为层间并行流水线并行和层内并行张量并行层间并行将模型的各个层分阶段处理并将每个阶段分布在不同的计算设备上层内并行则将计算图层内的参数切分到不同设备。分布式训练过程。 任务拆分与数据分配将训练任务拆分成多个子任务并将训练数据集分配给不同的计算节点。 模型复制与初始化在每个计算节点上复制神经网络模型的完整副本并进行初始化。 前向计算与梯度计算每个计算节点根据本地数据子集进行前向计算得到预测结果根据预测结果和真实标签计算损失函数并通过反向传播得到梯度。 梯度聚合与模型更新所有计算节点需要聚合其他节点计算的梯度值使用平均梯度或其他方法对模型进行更新。 迭代与收敛重复上述步骤直到模型达到收敛或达到预设的迭代次数', '问yolov3放在硬件上是不是有些大一般工业上用的是比较轻量化的。答部署时候需要对模型进行剪枝模型从230M压缩到30M左右精度损失了不到1', '问简述一下链式求导法则。答链式求导法则主要用于复合函数的求导在深度学习中 一个神经网络可以看作一个巨大的复合函数在对隐藏层进行求导时无法直接求出根据输出层损失函数求导利用链式求导法则可以推出隐藏层参数的偏导数从而实现对隐藏层求梯度', '问视频数据流怎么处理的。答视频数据主要用于抽帧或截取视频抽帧指利用视频处理库如OpenCV将视频分解为一系列帧每帧都是一个静态图像视频截取指截取出某个长度或时间段的视频用于后期处理', '问视频流里高亮问题比较常见这种情况一般怎么处理的。答视频流中的高亮问题通常指的是视频中某些部分如光源反光区域或特定物体的亮度过高导致细节丢失或视觉不适这种情况在视频处理监控视频分析以及视频编辑中较为常见以下是一些处理视频流中高亮问题的常用方法。1预处理阶段。 曝光控制在拍摄阶段通过调整摄像机的曝光设置如快门速度光圈大小和ISO值来控制视频的亮度。 白平衡调整正确的白平衡设置有助于减少视频中的色彩偏差使高光部分的颜色更加自然。2后处理阶段。 亮度调节使用视频编辑软件或专门的视频处理库如OpenCV对视频进行亮度调节。 对比度调整增加对比度可以增强视频中的明暗对比使高光部分更加突出但也可能导致细节丢失。 高光抑制应用高光抑制算法或滤镜来减少视频中的高光部分这些算法通常通过降低高亮区域的亮度并增强周围区域的亮度来减少高光的影响。 色彩校正使用色彩校正工具对视频进行色彩调整以恢复因高亮而丢失的色彩细节。3高级处理技术。 HDR高动态范围技术HDR技术可以捕捉和显示更广泛的亮度范围从而减少高亮部分对视频质量的影响。 色调映射色调映射是一种将HDR视频转换为LDR低动态范围视频的技术通过色调映射算法可以保留HDR视频中的高光和暗部细节同时使其在LDR设备上也能呈现出良好的视觉效果', '问模型训练的数据都是512512的如果数据是几公里乘几公里的这么大范围数据如何处理。答对整个大图像进行裁剪裁剪维512512识别完成后再将识别结果转换为整个图像坐标系下进行显示', '问Python和C的区别。答主要有以下区别。 C是编译型语言Python是解释型语言。 C运行速度快效率高Python运行速度慢效率低。 C适合跟硬件互动Python适合做应用层开发。 C适合嵌入式操作系统等底层软件Python适合数据科学AI科学计算等应用层软件。语言本身并无优劣在项目中根据实际情况选择合适的语言来解决问题', '问你在这个项目里具体是做什么的 。答主要负责数据收集标注预处理算法相关问题的分析算法选型模型训练评估优化部署集成集成测试后期维护', '问你知道为什么用TensorFlow框架不用其他的吗 。答深度学习框架之间并没有太多的区别这个项目之前一直就是用Tensorflow所以一直沿用使用同一框架开发维护都比较方便', '问你们这个项目里样本的分辨率是多少。答数据采集时候各种分辨率都有只是输入模型中需要缩放为相同大小', '问最开始的照片是高清的你是怎么处理成256256的。答通过图像库进行裁剪缩放', '问有什么常用的图像分割算法吗。答我比较熟悉UnetDeepLab系列实例级检测有Mask RCNN我平时也比较关注分割领域一些新的模型例如SAM这个模型在通用分割领域使用还可以在专业领域例如工业领域用的少一些', '问如果样本里有污点你们是怎么处理的。答少量的污点可以不用处理如果污点数量较多但是没有影响图像主要特征也不需要处理如果影响主要特征可以使用图像软件将污点去掉', '问有误检的情况吗怎么处理的。答有误检和漏检情况如果出现这种情况需要先分析是什么原因导致的然后进行模型优化优化方式主要从数据模型参数方面进行优化', '问为什么选择VGG作为主干网络用的是多少层进行了哪些修改。答VGG模型深度适中识别能力较强所以选择这个作为骨干网主要使用卷积池化部分', '问知不知道一些GPU的型号包括GPU的显存这一方面。答目前GPU主要是Nvidia生产的Nvidia显卡主要包括以下三类。 Geforce消费级显卡主要面向PC机和游戏市场包含RTX20RTX30RTX40系列价格几千元。 深度学习显卡主要针对高性能计算和人工智能领域被广泛应用于科学计算深度学习大规模数据分析等领域主流热门显卡如Tesla V100Tesla A100 Tesla H100价格在几万到几十万元。 边沿计算显卡主要针对边沿计算设备在低功耗嵌入式设备下运行主要是Nvidia Jetson系列价格在几百到几千元', '问用GPU训练的时候有没有注意GPU的占用情况等信息。答注意到可以使用nvidiasmi命令查看当前GPU使用情况', '问有没有出现过训练过程中出现报错原因是GPU空间占满了的情况。答有出错的情况例如图片或数据读取不到数据异常内存占满GPU占满的情况是因为批次调太大或模型参数过大导致的可以调小批次也可能是因为内存回收机制不当导致', '问在训练VGG是的batchsize是多少训练了多少轮。答VGG模型参数量较大1314亿所以训练时候需要将批次设置小点大约432之间训练轮次取决于收敛情况一般数百轮实际中是不断做增量训练', '问有没有对学习率做过调整。答在训练过程中会经常做学习率调整例如刚开始学习率设置大一点训练一段时间后调小', '问使用的是什么优化器优化器的参数设置是怎样的SGD有哪些参数SGD随机梯度下降和GD梯度下降有什么区别。答选择优化器时一般根据论文里给出的推荐优化器如果自己选择一般选Adam或RMSProp综合性能较好SGD优化器即原始随机梯度下降优化器主要参数有批次大小学习率GD和SGD一般指同一个意思', '问对于Momentum的参数有什么看法因为一般需要调节它的动量动量值设置成多大效果会比较好。答Momentum动量优化器在更新梯度时增加上一次的梯度表达式如下。Delta w_ji ln   eta delta_i l1 x_j l n  alpha Delta w_ji l n1。其中Delta w_ji ln为本次更新的步幅由本轮梯度和学习率的乘积 eta delta_i l1 x_j l n再加上一次更新的步幅 Delta w_ji l n1alpha控制权重动量参数alpha通常设置为一个介于0和1之间的值常见的设置包括050809和099等。问VGG的网络结构是怎样的为什么要连续两次卷积之后在进行池化为什么不是一次卷积连着一次池化。答1主要结构特征VGG主要有两种规格VGG16和VGG1916和19表示有参数的层数前面连续5组卷积池化后跟3个全连接层VGG的特点是反复卷积每个卷积层都采用33卷积核步长1填充1每个池化层采用22池化步长为2。2为什么不每个卷积层后加池化连续几个卷积层能学习到更多特征如果每个卷积层后加池化特征图就会缩小很快丢失一些重要特征', '问VGG模型为什么要用33的卷积核因为AlexNet是77的卷积核VGG用33的卷积核的意义是什么。答33卷积核有以下几个优点。 参数规模更小。 能学习到更多细节特征。 从感受野大小来讲3层33卷积可以获得和一层77相同 的感受野前者有33327个参数后者7749个参数前者参数量更小', '问VGG模型中为什么卷积核的个数要依次成倍递增。答随着卷积池化层数增加特征图越来越小为了保持模型学习能力所以卷积核数量增加卷积核数量翻倍只是一个习惯性用法不一定要成倍增加', '问为什么VGG最多能到19层为什么会梯度消失。答VGG网络最多能达到19层这一设计选择主要是基于对网络深度和性能之间平衡的考虑深度神经网络梯度消失的原因主要是受反向传播链式法则影响梯度需要逐层相乘如果层数很多那么梯度会不断被小于1的值缩小导致逐层衰减', '问OpenCV中的开运算和闭运算两者的效果之间的区别一阶段梯度算子和二阶段梯度算子的区别。答1开运算先腐蚀再膨胀开运算能够把比结构元素小的噪声和突刺过滤掉并切断细长的连接起到分离的作用例如将因噪声影响粘连在一起的区域分割开来闭运算就是先膨胀再腐蚀闭运算可以把比结构元素小的缺憾或者空洞补上将细小断裂的区域进行连通例如将因图像质量而断裂的目标区域进行合并连通。2一阶梯度算子是求图像灰度变化曲线的导数能够突出图像中的对象边缘二阶微分算子求图像灰度变化导数的导数二阶导数对图像中灰度变化强烈的地方很敏感从而可以突出图像的纹理结构', '问YOLOv3后处理的流程是怎样的。答YOLOv3的后处理流程主要包括网络输出处理阈值过滤以及非极大值抑制NMS等步骤。 网络输出处理YOLOv3模型在预测阶段会输出三个不同尺度的特征层结果这些特征层分别对应着不同大小的目标检测对于每个特征层模型会输出一系列预测框bounding boxes及其相关的置信度和类别概率。 阈值过滤首先根据设定的置信度阈值如05或更高过滤掉那些置信度较低的预测框这一步可以显著减少后续处理的计算量并去除那些明显不可靠的预测结果对于每个保留下来的预测框还需要根据其类别概率进行过滤通常会选择概率最高的类别作为预测结果并再次应用一个阈值如09或更高来过滤掉那些类别概率较低的预测框。 非极大值抑制非极大值抑制是一种用于去除冗余预测框的技术从这些重叠的预测框中选择一个最优的预测框并去除其他冗余的预测框', '问项目流程是怎样的怎么选择的模型。答1项目流程。 问题定位分类回归图像分类目标检测图像分割NERSeq2Seq文本分类文本生成。 准备数据采集数据清洗标注增强。 定义模型找开源模型找不到才自己编写。 训练调优评估。 压缩裁剪部署。 后期维护。2如何选择模型。 问题定位属于哪一类问题。 性能指标时间指标精度指标。 寻找合适模型或算法如果不知道使用什么算法查阅论文', '问Canny和边沿检测的区别 。答边沿检测是一种图像技术目的是找出图像或物体的边沿Canny是检测边沿的一种算法除了Canny还有其它很多算法可以做边沿检测', '问项目是怎样进行部署的。答1部署方式有服务器部署终端部署嵌入式部署。2部署流程确定部署方式  模型压缩与优化  部署  测试', '问怎样隔离多套环境比如说在系统上有多个Python版本是怎样将它们隔离开的。答1隔离多套环境可以使用虚拟机或docker虚拟环境隔离多个环境。2如何隔离多个版本可以对每个项目新建一个虚拟解释器在虚拟解释器下进行包安装这样每个项目的软件包就可以不相互影响', '问Transformer的时间复杂度On2如何降低时间复杂度。答Transformer模型的时间复杂度主要由其自注意力SelfAttention机制引起该机制在处理序列长度为n的输入时时间复杂度为On2这是因为自注意力机制需要计算序列中每个元素对其他所有元素的注意力权重这导致了一个nn的注意力矩阵为了降低Transformer的时间复杂度研究者们提出了多种方法以下是一些常见的策略。 稀疏注意力设计一种机制使得只有相距一定距离的元素之间才能建立注意力连接。 线性注意力通过近似计算或利用数学变换将自注意力机制的时间复杂度从On2降低到On例如Performer模型就采用了核方法来近似注意力矩阵的计算从而实现了线性时间复杂度。 分块分层注意力ChunkedHierarchical Attention将输入序列分成多个块chunk并在块内或块间计算注意力这种方法可以显著减少需要计算的注意力权重数量但可能会牺牲一定的模型性能。 长短期记忆网络LSTM门控循环单元GRU与Transformer结合对于非常长的序列可以结合使用LSTMGRU等循环神经网络来捕捉序列的长期依赖关系并使用Transformer来处理较短的片段或局部信息这种方法可以平衡计算效率和模型性能。 自适应注意力跨度Adaptive Attention Span过训练一个额外的模型或模块来决定每个元素应该关注哪些其他元素从而动态地调整注意力矩阵的稀疏性这种方法可以根据输入数据的特性来灵活地调整计算量', '问学习率策略有哪些什么是学习率的预热。答学习率策略主要有。 固定学习率在训练过程中使用一个固定的学习率来更新模型参数这种方法简单直接但可能无法适应训练过程中的动态变化容易导致模型过早陷入局部最优或在全局最优点附近震荡。 时间衰减策略根据训练迭代次数或其他因素逐渐减小学习率以加速模型收敛并避免过拟合。 自适应学习率根据模型参数的梯度或其他信息来动态调整学习率。此外还有一种特殊的学习率策略学习率预热Learning Rate Warmup学习率预热通常会使用线性或指数函数逐渐增加学习率并遵循以下步骤。 设定初始学习率确定一个较小的初始学习率该学习率用于在训练的初期阶段进行参数更新。 预热步骤在预热步骤中学习率逐渐增加通常使用线性或指数函数来设置学习率增加的速度确保在一定的训练步骤内逐渐达到设定的初始学习率。 正常训练在预热阶段结束后使用设定的初始学习率进行正常的训练过程继续训练模型并根据训练过程中的反馈动态调整学习率', '问如果给你一千万条的记录你会怎么来检索关键词。答采用并行化处理方式并行处理主要技术有多进程多线程多主机模式多进程指同一台机器运行多个进程每个进程负责检索一部分多线程指一个进程开多个线程每个线程负责一部分检索任务多主机指开多台主机每个主机负责检索一部分', '问描述一下yolo模型。答1YOLO是一阶段检目标测技术结构包括。 输入层做图像增强缩放归一化。 骨干网做特征提取。 特征融合对不同大小特征图做特征融合。 输出输出三种大小预测结果输出张量每个11的区域预测出3个候选框的类别定位和置信度。2YOLO目前发展到YOLO11比较流行的大版本有YOLO3YOLO5YOLO8。3YOLO的特点是能兼顾检测精度和速度', '问实际工作如何遇到精度达不到要求如何调整。答可以从以下四个方面进行优化。 数据优化如数据增强调整颜色亮度饱和度去除无关的部分。 模型优化选择更新精度更高的模型集成学习。 参数优化调整学习率批次大小正则强度丢弃率模型宽度高度等。 外部优化改善识别环境添加业务约束', '问您还有哪些问题需要问我们的。答最好问以下以下问题。 公司发展规划。 这个工作岗位未来发展情况', '问介绍一下项目用到哪些技术点功能点包括在项目中担任的角色。答。1技术点讲主要技术点例如本项目是使用XXX技术实现XXX功能采用XXX技术开发XXX框架。2项目中的角色项目角色大致有以下几类。 开发工程师负责程序编码自测维护文档编写。 维护工程师负责系统运维。 测试工程师负责功能性能测试。 算法工程师AI类项目才有负责算法分析选型训练优化。 部署工程师负责模型压缩优化部署。 项目管理岗位项目管理协调沟通进度质量成本管理。 产品经理负责需求收集分析产品功能性能参数涉及产品宣传推广产品开发推广计划指定。根据自己实际情况项目情况进行回答', '问项目中使用到什么类型的工业相机去拍摄是用线阵相机还是面阵相机。答工业中面阵相机使用较多根据不同的分类标准可以分为多种类型以下是一些常见的工业相机种类。1按靶面类型分类。 面阵相机可以一次性采集获取完整的二维图像信息测量图像直观广泛应用于面积形状尺寸位置等检测应用中。 线阵相机顾名思义就是所探测的物体要在一个很长的界面上线阵相机的传感器只有一行感光像素所以线阵相机一般具有非常高的扫描频率和分辨率 线阵CCDCMOS的优点是一维像元数可以做得很多而且像元尺寸比较灵活行频高特别适用于一维动态目标的测量通常在如下情况下需要考虑使用线阵相机被测视野为细长的带状多用于滚筒上检测的问题需要极大的视野或极高的精度。2按芯片类型分类。 CCD电荷耦合器件相机具有较高的灵敏度和信噪比体积小重量轻低功耗响应速度快像素集成度高适用于对图像质量要求较高的场合。 CMOS互补金属氧化物半导体相机具有较低的成本和功耗高速成像高帧率高性价比适用于大规模量产和便携式设备以及需要高帧率成像的场合。3按输出图像颜色分类。 黑白相机在相同分辨率下相比彩色相机精度更高检测图像边缘时成像效果更好适用于光线较暗或需要高对比度图像的场合。 彩色相机适用于需要颜色信息的场合如印刷检测和食品分级。4其它类型。 智能相机高度集成的光学检测工具包括工业机器视觉系统的所有元素将图像采集处理与通信功能集成于单一相机内用于控制质量和提高生产率可以封装一些简单的图像处理算法模块。 3D相机能够获取被分析物体的三维信息适用于需要测量被分析物体的体积形状或3D位置的应用情景。 红外相机基于红外光的辐射和反射原理进行工作的特殊相机用于热成像夜晚场景', '问有没有自己安装调试工业相机。答开发环境中是我自己搭建的实际上线有专门的支持工程师支持工程师有问题会找开发工程师协助', '问讲一下项目实施的过程。答人工智能项目和普通项目实施过程没有太大区别主要包括。 需求分析明确AI系统需要解决的问题确定项目的目标和预期效果。 可行性分析评估项目的技术可行性成本效益以及潜在风险这包括选择合适的编程语言开发平台和算法框架以及制定项目的时间表和预算。 系统设计设计系统的整体架构包括数据流算法选择系统模块划分等。 数据准备数据收集清洗标注数据集划分数据增强。 模型开发问题定位算法选择模型搭建训练调优。 测试与评估单元测试集成测试性能测试AI模型评估精度召回率速度等。 部署与集成将训练好的模型集成到实际项目中与现有系统实现对接。 后期运营与维护包括系统监控数据更心用户反馈模型与系统升级。 文案编写开发类文档产品类文档品牌宣传类文档', '问模型训练有没有用到深度学习模型有没有用到传统学习算法。答1真实项目中一般使用使用深度学习模型因为深度学习模型精度更高泛化能力更强。2某些特殊情况下可以选择传统学习算法例如样本较少可以使用传统机器学习算法在光源稳定大小一致干扰较少的工业检测场景中可以使用纯图像技术', '问有没有通过一些传统的逻辑算法来提优。答根据实际情况来回答例如项目案例库中锂电池隔膜检测案例就使用了传统图像算法来进行初选然后跟深度学习模型进行分割', '问项目中有没有判断是否有缺陷缺陷长度大小面积是如何判断的。答1如果只判断有无缺陷采用图像分类技术即可。2如果要检测缺陷长度大小面积需要采用图像分割技术然后根据相机位置分辨率进行转换将图像中的大小计算转换为实际大小', '问与其他部门人员的配合问题特别是现场交付的时候。答项目交付由整个项目组协同客户进行一般交付过程。 对项目产出进行评审评审功能性能以及其它各项指标是否达到了设计要求。 项目成果交付交付项目产出成果包括程序数据文档硬件设置。 用户培训。 问题反馈调整。交付过程中一般采用同级别人员沟通的方式 本方经理跟对方经理本方工程师跟对方工程师遇到本级别人员不能协调的问题向上级汇报协同沟通解决', '问模型检测远处物体置信度高近处物体置信度低是因为什么。答在深度学习目标检测模型中出现远处物体置信度高而近处物体置信度低的现象可能由多种因素导致。 目标尺寸与锚框匹配度在目标检测中通常会使用一系列预设的锚框Anchor Boxes来作为候选框这些锚框具有不同的尺寸和比例用于匹配不同大小和形状的目标如果近处物体的尺寸与预设锚框的尺寸不匹配那么模型可能难以准确地预测这些物体的边界框从而导致较低的置信度相反远处物体如果与某个锚框的尺寸较为接近则可能获得更高的置信度。 特征提取与分辨率深度学习模型通常通过卷积神经网络CNN来提取图像特征随着网络的深入特征的分辨率通常会逐渐降低对于近处物体由于其细节丰富且占据图像中的较大区域模型可能无法充分捕捉这些细节信息导致置信度下降远处物体虽然细节较少但可能在较低分辨率的特征图上仍然保持足够的识别信息因此模型能够给出较高的置信度。 遮挡与背景干扰近处物体可能更容易受到遮挡或背景干扰的影响例如物体可能被其他物体部分遮挡或者其背景与物体颜色相近导致模型难以准确区分。 训练数据不均衡如果训练数据集中远处物体的数量多于近处物体或者远处物体的标注更为准确和完整那么模型可能更倾向于对远处物体给出更高的置信度。为了解决这一问题可以尝试以下方法。 优化锚框的尺寸和比例以更好地匹配不同大小和形状的目标。 使用更高分辨率的特征图或采用特征金字塔网络FPN等结构来增强模型对近处物体的检测能力。 增加训练数据中近处物体的数量和多样性并改进标注质量。 采用更先进的模型结构和训练策略来提高模型的泛化能力', '问提升YOLOV5模型的查准率召回率怎么做。答深度学习模型可以从数据模型参数外部条件等方面进行优化。1数据优化。 增加训练数据的质量和数量。 收集更多样化的训练样本包括不同角度光照条件背景和尺寸的图像。 对数据进行仔细标注确保标注的准确性和完整性。 使用数据增强技术如旋转缩放裁剪和翻转等来增加数据的多样性和数量。2模型优化。 选择更大的模型在计算资源允许的情况下使用更大的YOLOv5模型如YOLOv5x通常会产生更好的结果。 尝试不同的网络架构优化算法和超参数设置来改进模型的性能。 引入注意力机制和残差连接。 优化Neck部分Neck是YOLO模型中负责融合不同尺度特征的网络部分优化Neck可以增强模型的多尺度特征融合能力从而减少错报。3参数优化。 调整学习率。 dropout比例。 卷积核大小膨胀卷积膨胀率。 训练轮数。4外部 优化。 改善识别时候的光照角度。 减少干扰因素']